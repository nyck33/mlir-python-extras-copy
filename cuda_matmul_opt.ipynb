{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyck33/mlir-python-extras-copy/blob/main/cuda_matmul_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile using MLIR but run using CuPy\n",
        "## (select `Runtime -> Change Runtime Type -> GPU`)"
      ],
      "metadata": {
        "id": "wY9YBePv7e2L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jho6_tne3pzT",
        "outputId": "84e01cca-ca77-4b63-f3c8-2eb14f955584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mlir-python-extras (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q cupy-cuda12x==13.0.0\n",
        "!pip install -q mlir_python_bindings==19.0.0.2024042100+cuda.b6824c9d -f https://makslevental.github.io/wheels/\n",
        "!pip install -q git+https://github.com/makslevental/mlir-python-extras@8b813f25b0254b4fa43d1dd254645d1512ae5ec6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boilerplate"
      ],
      "metadata": {
        "id": "fqMTzhQV5IuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import contextlib\n",
        "import math\n",
        "from typing import TypeVar\n",
        "\n",
        "import cupy as cp\n",
        "import mlir.extras.types as T\n",
        "import numpy as np\n",
        "from cupy.cuda import Module\n",
        "\n",
        "from mlir.extras.ast.canonicalize import canonicalize\n",
        "from mlir.extras.context import (\n",
        "    mlir_mod_ctx,\n",
        "    MLIRContext,\n",
        ")\n",
        "from mlir.extras.dialects.ext import arith, memref, gpu, scf, linalg, vector\n",
        "from mlir.extras.dialects.ext.gpu import (\n",
        "    block_idx,\n",
        "    thread_idx,\n",
        "    block_dim,\n",
        "    get_compile_object_bytes,\n",
        ")\n",
        "from mlir.extras.dialects.ext.memref import S\n",
        "from mlir.extras.dialects.ext.scf import range_\n",
        "from mlir.extras.runtime.passes import Pipeline, run_pipeline\n",
        "from mlir.extras.util import find_ops, enable_debug as enable_debug"
      ],
      "metadata": {
        "id": "j61WdIaI3xd7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "M535tCOOKQQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cuda_func(compiled_module, kernel_name=\"naive\"):\n",
        "    ptx = get_compile_object_bytes(compiled_module)\n",
        "    mod = Module()\n",
        "    mod.load(ptx)\n",
        "    return mod.get_function(kernel_name)\n",
        "\n",
        "\n",
        "def print_ptx(compiled_module):\n",
        "    ptx = get_compile_object_bytes(compiled_module)\n",
        "    print(ptx.decode())\n",
        "\n",
        "\n",
        "def compile_module(module, enable_ir_printing=False, print_ptx_=False):\n",
        "    if enable_ir_printing:\n",
        "        print_ptx_ = True\n",
        "    mod = run_pipeline(\n",
        "        module,\n",
        "        # if you're not using vectors you can just uncomment the gpu-lower-to-nvvm-pipeline below\n",
        "        Pipeline()\n",
        "        .convert_linalg_to_loops()\n",
        "        .convert_nvgpu_to_nvvm()\n",
        "        .gpu_kernel_outlining()\n",
        "        .convert_vector_to_scf()\n",
        "        .convert_scf_to_cf()\n",
        "        .convert_nvvm_to_llvm()\n",
        "        .convert_func_to_llvm()\n",
        "        .expand_strided_metadata()\n",
        "        .add_pass(\n",
        "            \"nvvm-attach-target\",\n",
        "            **{\n",
        "                \"chip\": \"sm_70\",\n",
        "                \"features\": \"+ptx76\",\n",
        "                \"O\": \"2\",\n",
        "            },\n",
        "        )\n",
        "        .lower_affine()\n",
        "        .convert_arith_to_llvm()\n",
        "        .convert_index_to_llvm()\n",
        "        .canonicalize()\n",
        "        .cse()\n",
        "        .Gpu(\n",
        "            Pipeline()\n",
        "            .strip_debuginfo()\n",
        "            # TODO(max): upstream this (add to gpu pipeline)\n",
        "            # vector.transfer\n",
        "            .convert_vector_to_llvm()\n",
        "            .convert_gpu_to_nvvm(use_bare_ptr_memref_call_conv=True)\n",
        "            .canonicalize()\n",
        "            .cse()\n",
        "            .reconcile_unrealized_casts()\n",
        "        )\n",
        "        .gpu_to_llvm(use_bare_pointers_for_kernels=True)\n",
        "        .gpu_module_to_binary(format=\"isa\")\n",
        "        .canonicalize()\n",
        "        .cse()\n",
        "        .reconcile_unrealized_casts()\n",
        "        # .add_pass(\n",
        "        #     \"gpu-lower-to-nvvm-pipeline\",\n",
        "        #     # https://github.com/llvm/llvm-project/blob/ace69e6b942b8fa7e610d70be2a92e801ceea481/mlir/include/mlir/Dialect/GPU/Pipelines/Passes.h#L18\n",
        "        #     **{\n",
        "        #         \"cubin-chip\": \"sm_80\",\n",
        "        #         \"cubin-features\": \"+ptx83\",\n",
        "        #         \"cubin-format\": \"isa\",\n",
        "        #         \"kernel-bare-ptr-calling-convention\": \"1\",\n",
        "        #         \"opt-level\": \"2\",\n",
        "        #         # \"cubin-format\": \"fatbin\",\n",
        "        #         # \"cubin-format\": \"bin\",\n",
        "        #     },\n",
        "        # )\n",
        "        ,\n",
        "        enable_ir_printing=enable_ir_printing,\n",
        "    )\n",
        "\n",
        "    if print_ptx_:\n",
        "        print_ptx(mod)\n",
        "\n",
        "    return mod\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def time_cuda():\n",
        "    start_gpu = cp.cuda.Event()\n",
        "    end_gpu = cp.cuda.Event()\n",
        "\n",
        "    start_gpu.record()\n",
        "    yield start_gpu, end_gpu\n",
        "    end_gpu.record()\n",
        "    end_gpu.synchronize()\n",
        "\n",
        "def prepare_non_tiled_kernel(ctx: MLIRContext, kernel, M, K, N, BLOCK_SIZE=32):\n",
        "    dtype = T.f32()\n",
        "    npy_dtype = np.float32\n",
        "\n",
        "    gpu.set_container_module(ctx.module)\n",
        "\n",
        "    @gpu.module(\"matmul\", [\"#nvvm.target\"])\n",
        "    def matmul_mod():\n",
        "        kernel[M, K, N, dtype, BLOCK_SIZE].emit()\n",
        "\n",
        "    # print(ctx.module)\n",
        "    # print(ctx.module.operation.verify())\n",
        "    # exit()\n",
        "\n",
        "    kernel_name = kernel.__name__\n",
        "    compiled_module = compile_module(ctx.module)\n",
        "    cuda_func = build_cuda_func(compiled_module, kernel_name)\n",
        "    # print_ptx(compiled_module)\n",
        "\n",
        "    grid_dims = (math.ceil(M / BLOCK_SIZE), math.ceil(N / BLOCK_SIZE))\n",
        "    block_dims = (BLOCK_SIZE, BLOCK_SIZE)\n",
        "\n",
        "    if \"shared\" in kernel_name:\n",
        "        shared_mem = 2 * BLOCK_SIZE * BLOCK_SIZE * npy_dtype().nbytes\n",
        "    else:\n",
        "        shared_mem = 0\n",
        "\n",
        "    return (\n",
        "        cuda_func,\n",
        "        grid_dims,\n",
        "        block_dims,\n",
        "        shared_mem,\n",
        "        npy_dtype,\n",
        "        \"transpose_B\" in kernel_name,\n",
        "    )\n",
        "\n",
        "def prepare_tiled_kernel(ctx: MLIRContext, kernel, M, K, N):\n",
        "    dtype = T.f32()\n",
        "    npy_dtype = np.float32\n",
        "    kernel_name = kernel.__name__\n",
        "\n",
        "    gpu.set_container_module(ctx.module)\n",
        "\n",
        "    BK = 8\n",
        "    TM = 8\n",
        "    TN = 8\n",
        "    if \"2d\" in kernel_name and M >= 128 and N >= 128:\n",
        "        BM = 128\n",
        "        BN = 128\n",
        "    else:\n",
        "        BM = 64\n",
        "        BN = 64\n",
        "\n",
        "    @gpu.module(\"matmul\", [\"#nvvm.target\"])\n",
        "    def matmul_mod():\n",
        "        kernel[M, K, N, dtype, BM, BN, BK, TM, TN].emit()\n",
        "\n",
        "    # print(ctx.module)\n",
        "    # print(ctx.module.operation.verify())\n",
        "    # exit()\n",
        "\n",
        "    compiled_module = compile_module(ctx.module)\n",
        "    cuda_func = build_cuda_func(compiled_module, kernel_name)\n",
        "    # print_ptx(compiled_module)\n",
        "\n",
        "    grid_dims = (math.ceil(N / BN), math.ceil(M / BM))\n",
        "    if \"2d\" in kernel_name:\n",
        "        block_dims = (BM // TM, BN // TN)\n",
        "    else:\n",
        "        block_dims = (BM // TM, BN)\n",
        "\n",
        "    if \"shared\" in kernel_name:\n",
        "        shared_mem = ((BM * BK) + (BK * BN)) * npy_dtype().nbytes\n",
        "    else:\n",
        "        shared_mem = 0\n",
        "\n",
        "    return (\n",
        "        cuda_func,\n",
        "        grid_dims,\n",
        "        block_dims,\n",
        "        shared_mem,\n",
        "        npy_dtype,\n",
        "        False,\n",
        "    )\n",
        "\n",
        "def prepare_warp_tiled_kernel(ctx: MLIRContext, kernel, M, K, N):\n",
        "    dtype = T.f32()\n",
        "    npy_dtype = np.float32\n",
        "    kernel_name = kernel.__name__\n",
        "\n",
        "    gpu.set_container_module(ctx.module)\n",
        "\n",
        "    # Settings for A100 (looks like it works for 3070 too?)\n",
        "    NUM_THREADS = 128\n",
        "    BN = 128\n",
        "    BM = 64\n",
        "    BK = 16\n",
        "    WN = 64\n",
        "    WM = 32\n",
        "    WNITER = 1\n",
        "    TN = 4\n",
        "    TM = 4\n",
        "\n",
        "    @gpu.module(\"matmul\", [\"#nvvm.target\"])\n",
        "    def matmul_mod():\n",
        "        kernel[M, K, N, dtype, BM, BN, BK, WM, WN, WNITER, TM, TN, NUM_THREADS].emit()\n",
        "\n",
        "    # print(ctx.module)\n",
        "    # print(ctx.module.operation.verify())\n",
        "    # exit()\n",
        "\n",
        "    compiled_module = compile_module(ctx.module)\n",
        "    cuda_func = build_cuda_func(compiled_module, kernel_name)\n",
        "    # print_ptx(compiled_module)\n",
        "\n",
        "    grid_dims = (math.ceil(N / BN), math.ceil(M / BM))\n",
        "    block_dims = (NUM_THREADS,)\n",
        "    shared_mem = ((BM * BK) + (BK * BN)) * npy_dtype().nbytes\n",
        "\n",
        "    return (\n",
        "        cuda_func,\n",
        "        grid_dims,\n",
        "        block_dims,\n",
        "        shared_mem,\n",
        "        npy_dtype,\n",
        "        False,\n",
        "    )\n",
        "\n",
        "def run_eval(\n",
        "    M,\n",
        "    K,\n",
        "    N,\n",
        "    cuda_func,\n",
        "    grid_dims,\n",
        "    block_dims,\n",
        "    shared_mem,\n",
        "    npy_dtype,\n",
        "    transpose_B,\n",
        "    repeat_times=None,\n",
        "):\n",
        "    if repeat_times is None:\n",
        "        repeat_times = 50\n",
        "\n",
        "    A = np.random.randint(0, 10, (M, K)).astype(npy_dtype)\n",
        "    B = np.random.randint(0, 10, (K, N)).astype(npy_dtype)\n",
        "    C = np.zeros((M, N)).astype(npy_dtype)\n",
        "\n",
        "    dA = cp.asarray(A)\n",
        "    if transpose_B:\n",
        "        dB = cp.asarray(np.ascontiguousarray(B.T))\n",
        "    else:\n",
        "        dB = cp.asarray(B)\n",
        "    dC = cp.asarray(C)\n",
        "\n",
        "    cuda_func(\n",
        "        grid_dims,\n",
        "        block_dims,\n",
        "        (dA.data.ptr, dB.data.ptr, dC.data.ptr),\n",
        "        shared_mem=shared_mem,\n",
        "    )\n",
        "    C = cp.asnumpy(dC)\n",
        "    if not np.array_equal(C, A @ B + 1):\n",
        "        print(A @ B + 1)\n",
        "        print(C)\n",
        "        assert False\n",
        "    if repeat_times < 1:\n",
        "        return\n",
        "\n",
        "    with time_cuda() as (start_gpu, end_gpu):\n",
        "        for _ in range(repeat_times):\n",
        "            cuda_func(\n",
        "                grid_dims,\n",
        "                block_dims,\n",
        "                (dA.data.ptr, dB.data.ptr, dC.data.ptr),\n",
        "                shared_mem=shared_mem,\n",
        "            )\n",
        "\n",
        "    t_gpu = cp.cuda.get_elapsed_time(start_gpu, end_gpu)\n",
        "\n",
        "    print(f\"t={t_gpu / repeat_times:.6f} ms\")\n"
      ],
      "metadata": {
        "id": "lBaiwflQKR4Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Kernels"
      ],
      "metadata": {
        "id": "QWXEKnCQ5RNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M, K, N, dtype, BLOCK_SIZE = list(map(TypeVar, [\"M\", \"K\", \"N\", \"dtype\", \"BLOCK_SIZE\"]))\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_naive(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "    tmp = arith.constant(0, type=dtype)\n",
        "\n",
        "    r = block_dim.x * block_idx.x + thread_idx.x\n",
        "    c = block_dim.y * block_idx.y + thread_idx.y\n",
        "\n",
        "    for k, tmp in range_(K, iter_args=[tmp]):\n",
        "        tmp += A[r, k] * B[k, c]\n",
        "        tmp = yield tmp\n",
        "    C[r, c] = tmp + one\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_naive_row_order(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "    tmp = arith.constant(0, type=dtype)\n",
        "\n",
        "    c = block_dim.x * block_idx.x + thread_idx.x\n",
        "    r = block_dim.y * block_idx.y + thread_idx.y\n",
        "\n",
        "    for k, tmp in range_(K, iter_args=[tmp]):\n",
        "        tmp += A[r, k] * B[k, c]\n",
        "        tmp = yield tmp\n",
        "    C[r, c] = tmp + one\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype, BLOCK_SIZE])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_coalesce(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "\n",
        "    tid = gpu.thread_id()\n",
        "    # this is actually floordiv\n",
        "    r = block_idx.x * BLOCK_SIZE + (tid / BLOCK_SIZE)\n",
        "    c = block_idx.y * BLOCK_SIZE + (tid % BLOCK_SIZE)\n",
        "    # gpu.printf(\"tid: %ld: (%ld, %ld)\\n\", tid, r, c)\n",
        "\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "    tmp = arith.constant(0, type=dtype)\n",
        "\n",
        "    for k, tmp in range_(K, iter_args=[tmp]):\n",
        "        tmp += A[r, k] * B[k, c]\n",
        "        tmp = yield tmp\n",
        "    C[r, c] = tmp + one\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype, BLOCK_SIZE])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_coalesce_transpose_B(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "\n",
        "    tid = gpu.thread_id()\n",
        "    r = block_idx.x * BLOCK_SIZE + (tid / BLOCK_SIZE)\n",
        "    c = block_idx.y * BLOCK_SIZE + (tid % BLOCK_SIZE)\n",
        "\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "    tmp = arith.constant(0, type=dtype)\n",
        "\n",
        "    for k, tmp in range_(K, iter_args=[tmp]):\n",
        "        tmp += A[r, k] * B[c, k]\n",
        "        tmp = yield tmp\n",
        "    C[r, c] = tmp + one\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype, BLOCK_SIZE])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_shared_mem_block(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "    base = gpu.dynamic_shared_memory()\n",
        "    A_shared = memref.view(base, (BLOCK_SIZE, BLOCK_SIZE), dtype=dtype)\n",
        "    B_shared = memref.view(\n",
        "        base, (BLOCK_SIZE, BLOCK_SIZE), dtype=dtype, shift=BLOCK_SIZE * BLOCK_SIZE\n",
        "    )\n",
        "\n",
        "    tid = gpu.thread_id()\n",
        "    thread_row = tid / BLOCK_SIZE\n",
        "    thread_col = tid % BLOCK_SIZE\n",
        "\n",
        "    c_row = block_idx.x * BLOCK_SIZE\n",
        "    c_col = block_idx.y * BLOCK_SIZE\n",
        "\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "    tmp = arith.constant(0, type=dtype)\n",
        "\n",
        "    for bk_idx, tmp in range_(0, K, BLOCK_SIZE, iter_args=[tmp]):\n",
        "        A_ = A[c_row : c_row + BLOCK_SIZE, bk_idx : bk_idx + BLOCK_SIZE]\n",
        "        B_ = B[bk_idx : bk_idx + BLOCK_SIZE, c_col : c_col + BLOCK_SIZE]\n",
        "\n",
        "        A_shared[thread_row, thread_col] = A_[thread_row, thread_col]\n",
        "        B_shared[thread_row, thread_col] = B_[thread_row, thread_col]\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "        for k, tmp in range_(BLOCK_SIZE, iter_args=[tmp]):\n",
        "            tmp += A_shared[thread_row, k] * B_shared[k, thread_col]\n",
        "            tmp = yield tmp\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "        tmp = yield tmp\n",
        "\n",
        "    C_ = C[c_row : c_row + BLOCK_SIZE, c_col : c_col + BLOCK_SIZE]\n",
        "    C_[thread_row, thread_col] = tmp + one"
      ],
      "metadata": {
        "id": "f7CyY1kd5Rrm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiled Kernels"
      ],
      "metadata": {
        "id": "7UUupX1RPWK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BM, BN, BK, TM, TN = list(map(TypeVar, [\"BM\", \"BN\", \"BK\", \"TM\", \"TN\"]))\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype, BM, BN, BK, TM])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_shared_mem_1d_block_tiling(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "    base = gpu.dynamic_shared_memory()\n",
        "    A_shared = memref.view(base, (BM, BK), dtype=dtype)\n",
        "    B_shared = memref.view(base, (BK, BN), dtype=dtype, shift=BM * BK)\n",
        "\n",
        "    c_row = block_idx.y * BM\n",
        "    c_col = block_idx.x * BN\n",
        "\n",
        "    tid = gpu.thread_id()\n",
        "    thread_col = tid % BN\n",
        "    thread_row = tid / BN\n",
        "\n",
        "    inner_col_A = tid % BK  # warp-level GMEM coalescing\n",
        "    inner_row_A = tid / BK\n",
        "    inner_col_B = tid % BN  # warp-level GMEM coalescing\n",
        "    inner_row_B = tid / BN\n",
        "\n",
        "    thread_results = memref.alloca((TM,), dtype)\n",
        "    linalg.fill(0, thread_results)\n",
        "\n",
        "    for bk_idx in range_(0, K, BK):\n",
        "        # Move blocktile to beginning of A's row and B's column\n",
        "        A_ = A[c_row : c_row + BM, bk_idx : bk_idx + BK]\n",
        "        B_ = B[bk_idx : bk_idx + BK, c_col : c_col + BN]\n",
        "\n",
        "        A_shared[inner_row_A, inner_col_A] = A_[inner_row_A, inner_col_A]\n",
        "        B_shared[inner_row_B, inner_col_B] = B_[inner_row_B, inner_col_B]\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "        for dot_idx in range_(BK):\n",
        "            tmp_B = B_shared[dot_idx, thread_col]\n",
        "            for res_idx, tmp_B in range_(TM, iter_args=[tmp_B]):\n",
        "                thread_results[res_idx] += (\n",
        "                    A_shared[thread_row * TM + res_idx, dot_idx] * tmp_B\n",
        "                )\n",
        "                yield tmp_B\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "    C_ = C[c_row : c_row + BM, c_col : c_col + BN]\n",
        "    for res_idx in range_(TM):\n",
        "        C_[thread_row * TM + res_idx, thread_col] = thread_results[res_idx] + one\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype, BM, BN, BK, TM, TN])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_shared_mem_2d_block_tiling(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "    base = gpu.dynamic_shared_memory()\n",
        "    A_shared = memref.view(base, (BM, BK), dtype=dtype)\n",
        "    B_shared = memref.view(base, (BK, BN), dtype=dtype, shift=BM * BK)\n",
        "\n",
        "    c_row = block_idx.y * BM\n",
        "    c_col = block_idx.x * BN\n",
        "\n",
        "    total_results_blocktile = BM * BN\n",
        "    num_threads_blocktile = total_results_blocktile // (TM * TN)\n",
        "\n",
        "    tid = gpu.thread_id()\n",
        "    # BN/TN are the number of threads to span a column\n",
        "    thread_col = tid % (BN // TN)\n",
        "    thread_row = tid / (BN // TN)\n",
        "\n",
        "    inner_col_A = tid % BK  # warp-level GMEM coalescing\n",
        "    inner_row_A = tid / BK\n",
        "    stride_A = num_threads_blocktile // BK\n",
        "\n",
        "    inner_col_B = tid % BN  # warp-level GMEM coalescing\n",
        "    inner_row_B = tid / BN\n",
        "    stride_B = num_threads_blocktile // BN\n",
        "\n",
        "    thread_results = memref.alloca((TM, TN), dtype)\n",
        "    linalg.fill(0, thread_results)\n",
        "\n",
        "    reg_M = memref.alloca((TM,), dtype)\n",
        "    linalg.fill(0, reg_M)\n",
        "\n",
        "    reg_N = memref.alloca((TN,), dtype)\n",
        "    linalg.fill(0, reg_N)\n",
        "\n",
        "    for bk_idx in range_(0, K, BK):\n",
        "        A_ = A[c_row : c_row + BM, bk_idx : bk_idx + BK]\n",
        "        B_ = B[bk_idx : bk_idx + BK, c_col : c_col + BN]\n",
        "\n",
        "        for load_offset in range_(0, BM, stride_A):\n",
        "            A_shared[inner_row_A + load_offset, inner_col_A] = A_[\n",
        "                inner_row_A + load_offset, inner_col_A\n",
        "            ]\n",
        "        for load_offset in range_(0, BK, stride_B):\n",
        "            B_shared[inner_row_B + load_offset, inner_col_B] = B_[\n",
        "                inner_row_B + load_offset, inner_col_B\n",
        "            ]\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "        for dot_idx in range_(BK):\n",
        "            for i in range_(TM):\n",
        "                reg_M[i] = A_shared[thread_row * TM + i, dot_idx]\n",
        "            for i in range_(TN):\n",
        "                reg_N[i] = B_shared[dot_idx, thread_col * TN + i]\n",
        "\n",
        "            for res_idx_m in range_(TM):\n",
        "                for res_idx_n in range_(TN):\n",
        "                    thread_results[res_idx_m, res_idx_n] += (\n",
        "                        reg_M[res_idx_m] * reg_N[res_idx_n]\n",
        "                    )\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "    C_ = C[c_row : c_row + BM, c_col : c_col + BN]\n",
        "\n",
        "    for res_idx_m in range_(TM):\n",
        "        for res_idx_n in range_(TN):\n",
        "            C_[thread_row * TM + res_idx_m, thread_col * TN + res_idx_n] = (\n",
        "                thread_results[res_idx_m, res_idx_n] + one\n",
        "            )\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype, BM, BN, BK, TM, TN])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_shared_mem_2d_block_tiling_vectorize(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "    VECTOR_WIDTH = 4\n",
        "    DTYPE_WIDTH = dtype.width // 8\n",
        "\n",
        "    memref.assume_alignment(A, VECTOR_WIDTH * DTYPE_WIDTH)\n",
        "    memref.assume_alignment(B, VECTOR_WIDTH * DTYPE_WIDTH)\n",
        "    memref.assume_alignment(C, VECTOR_WIDTH * DTYPE_WIDTH)\n",
        "\n",
        "    base = gpu.dynamic_shared_memory()\n",
        "    base = memref.memory_space_cast(T.memref(S, element_type=T.i8()), base)\n",
        "\n",
        "    # transpose A\n",
        "    A_shared = memref.view(base, (BK, BM), dtype=dtype)\n",
        "    B_shared = memref.view(base, (BK, BN), dtype=dtype, shift=BM * BK)\n",
        "\n",
        "    c_row = block_idx.y * BM\n",
        "    c_col = block_idx.x * BN\n",
        "\n",
        "    tid = gpu.thread_id()\n",
        "    # BN/TN are the number of threads to span a column\n",
        "    thread_col = tid % (BN // TN)\n",
        "    thread_row = tid / (BN // TN)\n",
        "\n",
        "    # calculating the indices that this thread will load into SMEM\n",
        "    # we'll load 128bit / 32bit = 4 elements per thread at each step\n",
        "    inner_col_A = tid % (BK // VECTOR_WIDTH)  # warp-level GMEM coalescing\n",
        "    inner_row_A = tid / (BK // VECTOR_WIDTH)\n",
        "    inner_col_B = tid % (BN // VECTOR_WIDTH)  # warp-level GMEM coalescing\n",
        "    inner_row_B = tid / (BN // VECTOR_WIDTH)\n",
        "\n",
        "    thread_results = memref.alloca((TM, TN), dtype)\n",
        "    linalg.fill(0, thread_results)\n",
        "\n",
        "    reg_M = memref.alloca((TM,), dtype)\n",
        "    linalg.fill(0, reg_M)\n",
        "\n",
        "    reg_N = memref.alloca((TN,), dtype)\n",
        "    linalg.fill(0, reg_N)\n",
        "\n",
        "    for bk_idx in range_(0, K, BK):\n",
        "        A_ = A[c_row : c_row + BM, bk_idx : bk_idx + BK]\n",
        "        B_ = B[bk_idx : bk_idx + BK, c_col : c_col + BN]\n",
        "\n",
        "        A_vec = vector.load(\n",
        "            T.vector(VECTOR_WIDTH, dtype), A_, [inner_row_A, inner_col_A * VECTOR_WIDTH]\n",
        "        )\n",
        "        for j in range(VECTOR_WIDTH):\n",
        "            #  transpose A while loading it\n",
        "            A_shared[inner_col_A * VECTOR_WIDTH + j, inner_row_A] = A_vec[j]\n",
        "\n",
        "        B_vec = vector.load(\n",
        "            T.vector(VECTOR_WIDTH, dtype), B_, [inner_row_B, inner_col_B * VECTOR_WIDTH]\n",
        "        )\n",
        "        vector.store(B_vec, B_shared, [inner_row_B, inner_col_B * VECTOR_WIDTH])\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "        for dot_idx in range_(BK):\n",
        "            for i in range_(TM):\n",
        "                reg_M[i] = A_shared[dot_idx, thread_row * TM + i]\n",
        "\n",
        "            for i in range_(TN):\n",
        "                reg_N[i] = B_shared[dot_idx, thread_col * TN + i]\n",
        "\n",
        "            for res_idx_m in range_(TM):\n",
        "                for res_idx_n in range_(TN):\n",
        "                    thread_results[res_idx_m, res_idx_n] += (\n",
        "                        reg_M[res_idx_m] * reg_N[res_idx_n]\n",
        "                    )\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "    C_ = C[c_row : c_row + BM, c_col : c_col + BN]\n",
        "\n",
        "    for res_idx_m in range_(TM):\n",
        "        for res_idx_n in range_(0, TN, VECTOR_WIDTH):\n",
        "            tmp = vector.load(\n",
        "                T.vector(VECTOR_WIDTH, dtype),\n",
        "                C_,\n",
        "                [thread_row * TM + res_idx_m, thread_col * TN + res_idx_n],\n",
        "            )\n",
        "            for j in range(VECTOR_WIDTH):\n",
        "                tmp[j] = thread_results[res_idx_m, res_idx_n + j] + one\n",
        "            vector.store(\n",
        "                tmp, C_, [thread_row * TM + res_idx_m, thread_col * TN + res_idx_n]\n",
        "            )\n",
        "\n",
        "WM, WN, WNITER, NUM_THREADS = list(map(TypeVar, [\"WM\", \"WN\", \"WNITER\", \"NUM_THREADS\"]))\n",
        "WARP_SIZE = 32\n",
        "\n",
        "@gpu.func(generics=[M, K, N, dtype, BM, BN, BK, WM, WN, WNITER, TM, TN, NUM_THREADS])\n",
        "@canonicalize(using=(arith.canonicalizer, scf.canonicalizer))\n",
        "def sgemm_warp_tiling(A: T.memref(M, K, dtype), B: T.memref(K, N, dtype), C: T.memref(M, N, dtype)):\n",
        "    VECTOR_WIDTH = 4\n",
        "    DTYPE_WIDTH = dtype.width // 8\n",
        "\n",
        "    tid = gpu.thread_id()\n",
        "\n",
        "    memref.assume_alignment(A, VECTOR_WIDTH * DTYPE_WIDTH)\n",
        "    memref.assume_alignment(B, VECTOR_WIDTH * DTYPE_WIDTH)\n",
        "    memref.assume_alignment(C, VECTOR_WIDTH * DTYPE_WIDTH)\n",
        "\n",
        "    base = gpu.dynamic_shared_memory()\n",
        "    base = memref.memory_space_cast(T.memref(S, element_type=T.i8()), base)\n",
        "\n",
        "    # transpose A\n",
        "    A_shared = memref.view(base, (BK, BM), dtype=dtype)\n",
        "    B_shared = memref.view(base, (BK, BN), dtype=dtype, shift=BM * BK)\n",
        "\n",
        "    c_row = block_idx.y * BM\n",
        "    c_col = block_idx.x * BN\n",
        "\n",
        "    # Placement of the warp in the threadblock tile\n",
        "    warp_idx = tid / WARP_SIZE\n",
        "    warp_row = warp_idx / (BN // WN)\n",
        "    warp_col = warp_idx % (BN // WN)\n",
        "\n",
        "    # size of the warp subtile\n",
        "    WMITER = (WM * WN) // (WARP_SIZE * TM * TN * WNITER)\n",
        "    WSUBM = WM // WMITER\n",
        "    WSUBN = WN // WNITER\n",
        "\n",
        "    # Placement of the thread in the warp subtile\n",
        "    thread_idx_in_warp = tid % WARP_SIZE\n",
        "    thread_col_in_warp = thread_idx_in_warp % (WSUBN // TN)\n",
        "    thread_row_in_warp = thread_idx_in_warp / (WSUBN // TN)\n",
        "\n",
        "    # calculating the indices that this thread will load into SMEM\n",
        "    # we'll load 128bit / 32bit = 4 elements per thread at each step\n",
        "    inner_row_A = tid / (BK // VECTOR_WIDTH)\n",
        "    inner_col_A = tid % (BK // VECTOR_WIDTH)\n",
        "    row_stride_A = (NUM_THREADS * VECTOR_WIDTH) // BK\n",
        "    inner_row_B = tid / (BN // VECTOR_WIDTH)\n",
        "    inner_col_B = tid % (BN // VECTOR_WIDTH)\n",
        "    row_stride_B = NUM_THREADS // (BN // VECTOR_WIDTH)\n",
        "\n",
        "    # allocate thread-local cache for results in registerfile\n",
        "    thread_results = memref.alloca((WMITER * TM, WNITER * TN), dtype)\n",
        "    linalg.fill(0, thread_results)\n",
        "\n",
        "    reg_M = memref.alloca((WMITER, TM), dtype)\n",
        "    linalg.fill(0, reg_M)\n",
        "\n",
        "    reg_N = memref.alloca((WNITER, TN), dtype)\n",
        "    linalg.fill(0, reg_N)\n",
        "\n",
        "    for bk_idx in range_(0, K, BK):\n",
        "        A_ = A[c_row : c_row + BM, bk_idx : bk_idx + BK]\n",
        "        B_ = B[bk_idx : bk_idx + BK, c_col : c_col + BN]\n",
        "\n",
        "        for offset in range(0, BM - row_stride_A + 1, row_stride_A):\n",
        "            A_vec = vector.load(\n",
        "                T.vector(VECTOR_WIDTH, dtype),\n",
        "                A_,\n",
        "                [inner_row_A + offset, inner_col_A * VECTOR_WIDTH],\n",
        "            )\n",
        "            for j in range(VECTOR_WIDTH):\n",
        "                #  transpose A while loading it\n",
        "                A_shared[inner_col_A * VECTOR_WIDTH + j, inner_row_A + offset] = A_vec[j]\n",
        "\n",
        "        for offset in range(0, BK - row_stride_B + 1, row_stride_B):\n",
        "            B_vec = vector.load(\n",
        "                T.vector(VECTOR_WIDTH, dtype),\n",
        "                B_,\n",
        "                [inner_row_B + offset, inner_col_B * VECTOR_WIDTH],\n",
        "            )\n",
        "            vector.store(\n",
        "                B_vec, B_shared, [inner_row_B + offset, inner_col_B * VECTOR_WIDTH]\n",
        "            )\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "        for dot_idx in range_(BK):\n",
        "            for w_sub_row_idx in range_(WMITER):\n",
        "                for i in range_(TM):\n",
        "                    reg_M[w_sub_row_idx, i] = A_shared[\n",
        "                        dot_idx,\n",
        "                        warp_row * WM\n",
        "                        + w_sub_row_idx * WSUBM\n",
        "                        + thread_row_in_warp * TM\n",
        "                        + i,\n",
        "                    ]\n",
        "\n",
        "            for w_sub_col_idx in range_(WNITER):\n",
        "                for i in range_(TN):\n",
        "                    reg_N[w_sub_col_idx, i] = B_shared[\n",
        "                        dot_idx,\n",
        "                        warp_col * WN\n",
        "                        + w_sub_col_idx * WSUBN\n",
        "                        + thread_col_in_warp * TN\n",
        "                        + i,\n",
        "                    ]\n",
        "\n",
        "            for w_sub_row_idx in range_(WMITER):\n",
        "                for w_sub_col_idx in range_(WNITER):\n",
        "                    for res_idx_m in range_(TM):\n",
        "                        for res_idx_n in range_(TN):\n",
        "                            thread_results[\n",
        "                                w_sub_row_idx * TM + res_idx_m,\n",
        "                                w_sub_col_idx * TN + res_idx_n,\n",
        "                            ] += (\n",
        "                                reg_M[w_sub_row_idx, res_idx_m]\n",
        "                                * reg_N[w_sub_col_idx, res_idx_n]\n",
        "                            )\n",
        "\n",
        "        gpu.barrier()\n",
        "\n",
        "    one = arith.constant(1.0, type=dtype)\n",
        "\n",
        "    for w_sub_row_idx in range_(WMITER):\n",
        "        for w_sub_col_idx in range_(WNITER):\n",
        "            r = c_row + warp_row * WM + w_sub_row_idx * WSUBM\n",
        "            c = c_col + warp_col * WN + w_sub_col_idx * WSUBN\n",
        "            C_ = C[r : r + WSUBM, c : c + WSUBN]\n",
        "            for res_idx_m in range_(TM):\n",
        "                for res_idx_n in range_(0, TN, VECTOR_WIDTH):\n",
        "                    tmp = vector.load(\n",
        "                        T.vector(VECTOR_WIDTH, dtype),\n",
        "                        C_,\n",
        "                        [\n",
        "                            thread_row_in_warp * TM + res_idx_m,\n",
        "                            thread_col_in_warp * TN + res_idx_n,\n",
        "                        ],\n",
        "                    )\n",
        "                    for j in range(VECTOR_WIDTH):\n",
        "                        tmp[j] = (\n",
        "                            thread_results[\n",
        "                                w_sub_row_idx * TM + res_idx_m,\n",
        "                                w_sub_col_idx * TN + res_idx_n + j,\n",
        "                            ]\n",
        "                            + one\n",
        "                        )\n",
        "                    vector.store(\n",
        "                        tmp,\n",
        "                        C_,\n",
        "                        [\n",
        "                            thread_row_in_warp * TM + res_idx_m,\n",
        "                            thread_col_in_warp * TN + res_idx_n,\n",
        "                        ],\n",
        "                    )\n"
      ],
      "metadata": {
        "id": "raKcQ45KPX0j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and run and time"
      ],
      "metadata": {
        "id": "mjckPqXx5Uw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = [128, 256, 512, 1024]\n",
        "repeats = None\n",
        "\n",
        "for k in [\n",
        "    sgemm_naive,\n",
        "    sgemm_naive_row_order,\n",
        "    sgemm_coalesce,\n",
        "    sgemm_coalesce_transpose_B,\n",
        "    sgemm_shared_mem_block,\n",
        "]:\n",
        "    print(f\"\\n{k.__name__}\")\n",
        "    for s in sizes:\n",
        "        with (\n",
        "            mlir_mod_ctx() as ctx,\n",
        "            # enable_debug()\n",
        "        ):\n",
        "            print(f\"{s=}\", end=\" \")\n",
        "            cuda_func, grid_dims, block_dims, shared_mem, npy_dtype, transpose_B = (\n",
        "                prepare_non_tiled_kernel(ctx, k, s, s, s)\n",
        "            )\n",
        "            run_eval(\n",
        "                s,\n",
        "                s,\n",
        "                s,\n",
        "                cuda_func,\n",
        "                grid_dims,\n",
        "                block_dims,\n",
        "                shared_mem,\n",
        "                npy_dtype,\n",
        "                transpose_B,\n",
        "            )\n",
        "\n",
        "\n",
        "for k in [\n",
        "    sgemm_shared_mem_1d_block_tiling,\n",
        "    sgemm_shared_mem_2d_block_tiling,\n",
        "    sgemm_shared_mem_2d_block_tiling_vectorize,\n",
        "]:\n",
        "    print(f\"\\n{k.__name__}\")\n",
        "    for s in sizes:\n",
        "        with (\n",
        "            mlir_mod_ctx() as ctx,\n",
        "            # enable_debug()\n",
        "        ):\n",
        "            print(f\"{s=}\", end=\" \")\n",
        "            cuda_func, grid_dims, block_dims, shared_mem, npy_dtype, transpose_B = (\n",
        "                prepare_tiled_kernel(ctx, k, s, s, s)\n",
        "            )\n",
        "            run_eval(\n",
        "                s,\n",
        "                s,\n",
        "                s,\n",
        "                cuda_func,\n",
        "                grid_dims,\n",
        "                block_dims,\n",
        "                shared_mem,\n",
        "                npy_dtype,\n",
        "                transpose_B,\n",
        "            )\n",
        "\n",
        "print(f\"\\n{sgemm_warp_tiling.__name__}\")\n",
        "for s in sizes:\n",
        "    with (\n",
        "        mlir_mod_ctx() as ctx,\n",
        "        # enable_debug()\n",
        "    ):\n",
        "        print(f\"{s=}\", end=\" \")\n",
        "        cuda_func, grid_dims, block_dims, shared_mem, npy_dtype, transpose_B = (\n",
        "            prepare_warp_tiled_kernel(ctx, sgemm_warp_tiling, s, s, s)\n",
        "        )\n",
        "        run_eval(\n",
        "            s,\n",
        "            s,\n",
        "            s,\n",
        "            cuda_func,\n",
        "            grid_dims,\n",
        "            block_dims,\n",
        "            shared_mem,\n",
        "            npy_dtype,\n",
        "            transpose_B,\n",
        "        )\n"
      ],
      "metadata": {
        "id": "qZv2W8325f3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf158b3d-81bf-4704-85a0-fd4362d587e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "sgemm_naive\n",
            "s=128 t=0.242026 ms\n",
            "s=256 t=1.861219 ms\n",
            "s=512 t=7.477806 ms\n",
            "s=1024 t=35.405505 ms\n",
            "\n",
            "sgemm_naive_row_order\n",
            "s=128 t=0.016058 ms\n",
            "s=256 t=0.047639 ms\n",
            "s=512 t=0.314685 ms\n",
            "s=1024 t=2.675068 ms\n",
            "\n",
            "sgemm_coalesce\n",
            "s=128 t=0.016044 ms\n",
            "s=256 t=0.047667 ms\n",
            "s=512 t=0.314659 ms\n",
            "s=1024 t=2.614167 ms\n",
            "\n",
            "sgemm_coalesce_transpose_B\n",
            "s=128 t=0.090005 ms\n",
            "s=256 t=0.683334 ms\n",
            "s=512 t=4.657070 ms\n",
            "s=1024 t=35.379282 ms\n",
            "\n",
            "sgemm_shared_mem_block\n",
            "s=128 t=0.017633 ms\n",
            "s=256 t=0.039596 ms\n",
            "s=512 t=0.261349 ms\n",
            "s=1024 t=2.022630 ms\n",
            "\n",
            "sgemm_shared_mem_1d_block_tiling\n",
            "s=128 t=0.016317 ms\n",
            "s=256 t=0.030433 ms\n",
            "s=512 t=0.136143 ms\n",
            "s=1024 t=1.014650 ms\n",
            "\n",
            "sgemm_shared_mem_2d_block_tiling\n",
            "s=128 t=0.085923 ms\n",
            "s=256 t=0.204242 ms\n",
            "s=512 t=0.484605 ms\n",
            "s=1024 t=2.185633 ms\n",
            "\n",
            "sgemm_shared_mem_2d_block_tiling_vectorize\n",
            "s=128 t=0.076975 ms\n",
            "s=256 t=0.143140 ms\n",
            "s=512 t=0.384723 ms\n",
            "s=1024 t=2.289935 ms\n",
            "\n",
            "sgemm_warp_tiling\n",
            "s=128 t=0.047309 ms\n",
            "s=256 t=0.117632 ms\n",
            "s=512 t=0.245450 ms\n",
            "s=1024 t=1.281300 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELEbGysfithr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}