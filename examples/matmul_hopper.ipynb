{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyck33/mlir-python-extras-copy/blob/main/matmul_hopper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYfVip79KBd9"
      },
      "source": [
        "### Python Matmul\n",
        "requires Python bindings and MLIR so use the provided whl's from mlir-python-extras\n",
        "\n",
        "```bash\n",
        "! pip install mlir_python_bindings==19.0.0.2024032901+cuda.39e81374 -f https://makslevental.github.io/wheels/\n",
        "\n",
        "! pip install -q git+https://github.com/makslevental/mlir-python-extras.git\n",
        "```\n",
        "the above should work.  If not try any of the ones below and then install the second command above.\n",
        "\n",
        "```bash\n",
        "pip install mlir_python_bindings==19.0.0.2024032901+cuda.39e81374 -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032801+cuda.1095f71b -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032701+cuda.4720e383 -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032601+cuda.ce73b167 -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032501+cuda.cceedc93 -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032401+cuda.8e698a1d -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032301+cuda.2f6b1b4b -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032201+cuda.718fbbef -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032101+cuda.631248dc -f https://makslevental.github.io/wheels/\n",
        "pip install mlir_python_bindings==19.0.0.2024032001+cuda.09db84cc -f https://makslevental.github.io/wheels/\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbCr_FuHKNlr",
        "outputId": "8552ed03-7f67-4a0a-d1be-05ba5c973e3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mlir_python_bindings==19.0.0.2024032901+cuda.39e81374 -f https://makslevental.github.io/wheels/\n",
        "\n",
        "! pip install -q git+https://github.com/makslevental/mlir-python-extras.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDFZ6G5eKqO4",
        "outputId": "bb11f7e6-d102-494a-ef6e-14fa28c41c63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://makslevental.github.io/wheels/\n",
            "Collecting mlir_python_bindings==19.0.0.2024032901+cuda.39e81374\n",
            "  Downloading https://github.com/makslevental/wheels/releases/download/i/mlir_python_bindings-19.0.0.2024032901%2Bcuda.39e81374-cp310-cp310-manylinux_2_28_x86_64.whl (58.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mlir_python_bindings\n",
            "Successfully installed mlir_python_bindings-19.0.0.2024032901+cuda.39e81374\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mlir-python-extras (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export SUPPORT_LIB=/home/nyck33/miniconda3/envs/mlir-py39cuda12/lib/python3.9/site-packages/mlir/_mlir_libs/libmlir_cuda_runtime.so"
      ],
      "metadata": {
        "id": "inGTRsPpML4L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import site; print(site.getsitepackages())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSxSzIvhK3WD",
        "outputId": "40fd40c3-4b80-4031-b0a2-1c5f6b8a93e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3.10/dist-packages']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directories = ['/usr/local/lib/python3.10/dist-packages',\n",
        "               '/usr/lib/python3/dist-packages',\n",
        "               '/usr/lib/python3.10/dist-packages']\n",
        "\n",
        "for directory in directories:\n",
        "    print(f\"Contents of {directory}:\")\n",
        "    try:\n",
        "        for filename in os.listdir(directory):\n",
        "            if 'mlir' in filename.lower() or 'cuda' in filename.lower():\n",
        "                print(filename)\n",
        "    except PermissionError:\n",
        "        print(f\"Cannot access the contents of {directory}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "jXAylrNjLaun",
        "outputId": "570abdc6-b83f-4802-86a0-ba9e45c83341"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /usr/local/lib/python3.10/dist-packages:\n",
            "mlir\n",
            "mlir_python_bindings.libs\n",
            "mlir_python_extras-0.0.7.dist-info\n",
            "mlir_python_bindings-19.0.0.2024032901+cuda.39e81374.dist-info\n",
            "jaxlib-0.4.23+cuda12.cudnn89.dist-info\n",
            "cupy_cuda12x-12.2.0.dist-info\n",
            "Contents of /usr/lib/python3/dist-packages:\n",
            "Contents of /usr/lib/python3.10/dist-packages:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/usr/lib/python3.10/dist-packages'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8466149fbf51>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Contents of {directory}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'mlir'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/lib/python3.10/dist-packages'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlir_directory = '/usr/local/lib/python3.10/dist-packages/mlir'\n",
        "\n",
        "try:\n",
        "    mlir_subdirs = os.listdir(mlir_directory)\n",
        "    for subdir in mlir_subdirs:\n",
        "        full_path = os.path.join(mlir_directory, subdir)\n",
        "        if os.path.isdir(full_path):\n",
        "            print(f\"Contents of {full_path}:\")\n",
        "            for file in os.listdir(full_path):\n",
        "                if 'cuda_runtime' in file:\n",
        "                    print(file)\n",
        "                    cuda_runtime_path = os.path.join(full_path, file)\n",
        "                    print(f\"Path to CUDA runtime: {cuda_runtime_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Directory not found: {mlir_directory}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1rbNcVpL4fU",
        "outputId": "85ebb950-5a51-412c-95e3-66c480f7de97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /usr/local/lib/python3.10/dist-packages/mlir/_mlir_libs:\n",
            "libmlir_cuda_runtime.so\n",
            "Path to CUDA runtime: /usr/local/lib/python3.10/dist-packages/mlir/_mlir_libs/libmlir_cuda_runtime.so\n",
            "Contents of /usr/local/lib/python3.10/dist-packages/mlir/dialects:\n",
            "Contents of /usr/local/lib/python3.10/dist-packages/mlir/extras:\n",
            "Contents of /usr/local/lib/python3.10/dist-packages/mlir/runtime:\n",
            "Contents of /usr/local/lib/python3.10/dist-packages/mlir/__pycache__:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJzO1sImKBeC"
      },
      "source": [
        "### from matmul.py at\n",
        "https://github.com/llvm/llvm-project/blob/main/mlir/test/Integration/GPU/CUDA/sm90/python/matmul.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwvzsPQLKLbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZRc1b3nkKBeC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['SUPPORT_LIB'] = '/usr/local/lib/python3.10/dist-packages/mlir/_mlir_libs/libmlir_cuda_runtime.so'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Cuda/MLIR/python/tools')\n"
      ],
      "metadata": {
        "id": "AVCbgk6INaJT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Cuda/MLIR/python')\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LQ8MXbZOUKh",
        "outputId": "3b16e056-f2df-48fa-dafc-65ea69d7a0ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Cuda/MLIR/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "Du6TTgSLKBeE",
        "outputId": "d5869fb3-0a34-4787-dca3-7b7f4865bf42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===-- Running GEMM Multistage f32 += f16 * f16, Size 128x128x64, Tile 128x128x64, stages 1 --===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "\nNot equal to tolerance rtol=0.005, atol=0.1\n\nMismatched elements: 16212 / 16384 (99%)\nMax absolute difference: 38.00\nMax relative difference: 1.00\n x: array([[0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],\n       [0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],\n       [0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],...\n y: array([[-0.12, -0.37, -6.48, ..., 3.61, 8.94, 5.15],\n       [-1.41, -2.06, 1.64, ..., -6.07, -2.42, -10.24],\n       [-5.13, 7.31, -7.54, ..., -6.38, 15.14, 14.46],...",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c2d30967c074>\u001b[0m in \u001b[0;36m<cell line: 343>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;31m# CHECK: PASS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m \u001b[0mtest_short\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-c2d30967c074>\u001b[0m in \u001b[0;36mtest_short\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mN\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                     matmul(\n\u001b[0m\u001b[1;32m    291\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-c2d30967c074>\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(input_type, output_type, M, N, K, BLOCK_M, BLOCK_N, BLOCK_K, use_warp_specialization, saveIR, max_num_stages, print_results, no_verify)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PASS \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    795\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.005, atol=0.1\n\nMismatched elements: 16212 / 16384 (99%)\nMax absolute difference: 38.00\nMax relative difference: 1.00\n x: array([[0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],\n       [0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],\n       [0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],...\n y: array([[-0.12, -0.37, -6.48, ..., 3.61, 8.94, 5.15],\n       [-1.41, -2.06, 1.64, ..., -6.07, -2.42, -10.24],\n       [-5.13, 7.31, -7.54, ..., -6.38, 15.14, 14.46],..."
          ]
        }
      ],
      "source": [
        "# RUN: env SUPPORT_LIB=%mlir_cuda_runtime \\\n",
        "# RUN:   %PYTHON %s | FileCheck %s\n",
        "\n",
        "\n",
        "# ===--- GEMM Hopper Tensor Core Integration Test ---===\n",
        "#\n",
        "# This test aims to validate the correctness of the supported GEMM kernels in\n",
        "# NVGPU dialects, with current support for Multistage and Warp Specialization\n",
        "# kernels.\n",
        "# The test constructs and metaprograms IR using Python bindings, allowing\n",
        "# generic IR building. This flexibility enables changes to the shape,\n",
        "# tile size, or data type of the GEMM for testing purposes.\n",
        "# The entry function is `matmul`, where one can specify GEMM shape, tile size,\n",
        "# data type, GEMM algorithm (Multistage or Warp Specialization), and the maximum\n",
        "# number of stages.\n",
        "# Verification is done via numpy's matmul operation.\n",
        "#\n",
        "# Example:\n",
        "# matmul(input_type=np.float16,                # input types\n",
        "#        output_type=np.float32,               # output type\n",
        "#        M=4096, N=4096, K=4096,               # Shape\n",
        "#        BLOCK_M=128, BLOCK_N=128, BLOCK_K=64, # Tile Size\n",
        "#        use_warp_specialization=True,         # Enable Warp Specialization\n",
        "#        max_num_stages=3)                     # Number of stages in shared memory\n",
        "#\n",
        "# ===--- Parallelism Across CTAs  ---===\n",
        "#\n",
        "# GEMM includes three loops defining the shape of the GEMM, specified in the\n",
        "# `matmul` function.\n",
        "# The program builds IR using the following loop structure, tiling the loops\n",
        "# with the given tile size and parallelizing the two outermost loops into the\n",
        "# first and second dimensions of CTAs.\n",
        "#\n",
        "# for(bi = 0; i < M; i += BLOCK_M)          # parallelize across blockIdx.x\n",
        "#     for(bj = 0; j < N; j += BLOCK_N)      # parallelize across blockIdx.y\n",
        "#         for(bk = 0; k < K; K += BLOCK_K)\n",
        "#             for(i = bi; i < (bi + BLOCK_M); ++i)\n",
        "#                 for(j = bj; j < (bj + BLOCK_N); ++j)\n",
        "#                     for(k = bk; k < (bk + BLOCK_K); ++k)\n",
        "#\n",
        "# ===--- Multistage Kernel ---===\n",
        "#\n",
        "# This kernel launches a single warp group (128 threads). The primary thread\n",
        "# (pthread) requests load from TMA. Threads collectively wait for the data and\n",
        "# perform mma operations. After completing the shape, threads together store\n",
        "# first fragmented registers to shared memory, then from shared memory to global\n",
        "# memory; this part is called the epilogue.\n",
        "#\n",
        "# Execution Timeline of Multistage Kernel with 3 stages:\n",
        "# +-------+----------------+--------------------+--------------------+--------------------+-----+-----------------------+\n",
        "# |       |Prologue ---->   |MainLoop ---->                                                                  |Epilogue  |\n",
        "# +-------+----------------+--------------------+--------------------+--------------------+-----+-----------------------+\n",
        "# |pthread|[tma-0,1,2]     |[wait-0][mma][tma-2]|[wait-1][mma][tma-0]|[wait-2][mma][tma-1]| ... | [mma-wait] |[epilogue]|\n",
        "# |wgroup | ........       |[wait-0][mma]       |[wait-1][mma]       |[wait-2][mma]       | ... | [mma-wait] |[epilogue]|\n",
        "# +-------+----------------+--------------------+--------------------+--------------------+-----+-----------------------+\n",
        "#\n",
        "# ===--- Warp Specialization Kernel  ---===\n",
        "#\n",
        "# This kernel launches 2 warp groups (2x128 threads) per CTA, specializing one\n",
        "# as `producer warp group` and another as `consumer warp group`. The\n",
        "# `producer warp group` is responsible for requesting TMA load, while the\n",
        "# `consumer warp group` performs the mma operation. The epilogue section is\n",
        "# handled by the `consumer warp group` as its threads own the fragmented registers.\n",
        "#\n",
        "# Execution Timeline of Warp Specialization Kernel with 2 stages:\n",
        "# +--------+--------+---------+---------+---------+-----------------------+---+--------------+-----------------+\n",
        "# |        |MainLoop ---->                                                    | 1st Epilogue | 2nd Epilogue    |\n",
        "# +--------+--------+---------+---------+---------+-----------------------+---+--------------+-----------------+\n",
        "# |pthread1|[tma-0] | [tma-1] | [tma-0] | [tma-1] | ..........................| ...........  | [shmem->global] |\n",
        "# |wgroup1 | .......|         |         |         |                           |              | [shmem->global] |\n",
        "# +--------+--------+---------+---------+---------+-----------------------+---+--------------+-----------------+\n",
        "# |wgroup2 |[wait-0][mma], [wait-1][mma], [wait-0][mma], [wait-1][mma], ......| [reg->shmem] | [shmem->global]|\n",
        "# +--------+--------+---------+---------+---------+-----------------------+---+--------------+-----------------+\n",
        "\n",
        "import errno\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import ctypes\n",
        "from tools import nvgpucompiler\n",
        "from tools import matmulBuilder\n",
        "#from nvgpucompiler import NvgpuCompiler\n",
        "#from matmulBUilder import MatmulBuilder\n",
        "import contextlib\n",
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import ctypes\n",
        "from mlir import runtime as rt\n",
        "\n",
        "\n",
        "def generate_matmul(\n",
        "    input_type=np.float16,\n",
        "    output_type=np.float32,\n",
        "    M=4096,\n",
        "    N=4096,\n",
        "    K=4096,\n",
        "    BLOCK_M=128,\n",
        "    BLOCK_N=128,\n",
        "    BLOCK_K=64,\n",
        "    use_warp_specialization=True,\n",
        "    saveIR=False,\n",
        "    max_num_stages=3,\n",
        "    options=f\"cubin-chip=sm_90a cubin-features=+ptx80 opt-level=3\",\n",
        "):\n",
        "    with matmulBuilder.ir.Context() as ctx, matmulBuilder.ir.Location.unknown():\n",
        "        if use_warp_specialization:\n",
        "            mlir_nvgpu_module = matmulBuilder.generate_matmul_ws(\n",
        "                input_type,\n",
        "                output_type,\n",
        "                M,\n",
        "                N,\n",
        "                K,\n",
        "                BLOCK_M,\n",
        "                BLOCK_N,\n",
        "                BLOCK_K,\n",
        "                max_num_stages,\n",
        "            )\n",
        "        else:\n",
        "            mlir_nvgpu_module = matmulBuilder.generate_matmul_multistage(\n",
        "                input_type,\n",
        "                output_type,\n",
        "                M,\n",
        "                N,\n",
        "                K,\n",
        "                BLOCK_M,\n",
        "                BLOCK_N,\n",
        "                BLOCK_K,\n",
        "                max_num_stages,\n",
        "            )\n",
        "\n",
        "        mlir_nvgpu_module.operation.verify()\n",
        "\n",
        "        # Save generated IR\n",
        "        if saveIR:\n",
        "            # print(mlir_nvgpu_module)\n",
        "            original_stdout = sys.stdout\n",
        "            with open(\"gemm.mlir\", \"w\") as f:\n",
        "                sys.stdout = f\n",
        "                print(mlir_nvgpu_module)\n",
        "                sys.stdout = original_stdout\n",
        "\n",
        "        # Get compiler\n",
        "        support_lib = os.getenv(\"SUPPORT_LIB\")\n",
        "        if not os.path.exists(support_lib):\n",
        "            raise FileNotFoundError(\n",
        "                errno.ENOENT, os.strerror(errno.ENOENT), support_lib\n",
        "            )\n",
        "        compiler = nvgpucompiler.NvgpuCompiler(\n",
        "            options, opt_level=3, shared_libs=[support_lib]\n",
        "        )\n",
        "\n",
        "        # Compile\n",
        "        engine = compiler.compile_and_jit(mlir_nvgpu_module)\n",
        "        return engine\n",
        "\n",
        "\n",
        "def matmul(\n",
        "    input_type=np.float16,\n",
        "    output_type=np.float32,\n",
        "    M=128,\n",
        "    N=128,\n",
        "    K=128,\n",
        "    BLOCK_M=128,\n",
        "    BLOCK_N=128,\n",
        "    BLOCK_K=64,\n",
        "    use_warp_specialization=True,\n",
        "    saveIR=False,\n",
        "    max_num_stages=3,\n",
        "    print_results=False,\n",
        "    no_verify=False,\n",
        "):\n",
        "    # Print the configuration\n",
        "    required_stages = (M * K + K * N) // (BLOCK_M * BLOCK_K + BLOCK_K * BLOCK_N)\n",
        "    num_stages = min(required_stages, max_num_stages)\n",
        "    ity = \"f16\" if input_type == np.float16 else \"f32\"\n",
        "    oty = \"f16\" if output_type == np.float16 else \"f32\"\n",
        "    gemmty = \"Warp specialization\" if use_warp_specialization else \"Multistage\"\n",
        "    print(\n",
        "        \"===-- Running GEMM \"\n",
        "        + gemmty\n",
        "        + \" \"\n",
        "        + oty\n",
        "        + \" += \"\n",
        "        + ity\n",
        "        + \" * \"\n",
        "        + ity\n",
        "        + \", Size \"\n",
        "        + str(M)\n",
        "        + \"x\"\n",
        "        + str(N)\n",
        "        + \"x\"\n",
        "        + str(K)\n",
        "        + \", Tile \"\n",
        "        + str(BLOCK_M)\n",
        "        + \"x\"\n",
        "        + str(BLOCK_N)\n",
        "        + \"x\"\n",
        "        + str(BLOCK_K)\n",
        "        + \", stages \"\n",
        "        + str(num_stages)\n",
        "        + \" --===\"\n",
        "    )\n",
        "\n",
        "    # Build IR and compile\n",
        "    engine = generate_matmul(\n",
        "        input_type,\n",
        "        output_type,\n",
        "        M,\n",
        "        N,\n",
        "        K,\n",
        "        BLOCK_M,\n",
        "        BLOCK_N,\n",
        "        BLOCK_K,\n",
        "        use_warp_specialization,\n",
        "        saveIR,\n",
        "        num_stages,\n",
        "    )\n",
        "\n",
        "    # Allocate matrices and invoke the matmul\n",
        "    c = np.zeros((M, N), output_type)\n",
        "    a = np.random.randn(M, K).astype(input_type)\n",
        "    b = np.random.randn(K, N).astype(input_type)\n",
        "    mem_a = ctypes.pointer(ctypes.pointer(rt.get_ranked_memref_descriptor(a)))\n",
        "    mem_b = ctypes.pointer(ctypes.pointer(rt.get_ranked_memref_descriptor(b)))\n",
        "    mem_c = ctypes.pointer(ctypes.pointer(rt.get_ranked_memref_descriptor(c)))\n",
        "    kernelName = matmulBuilder.make_kernel_name(\n",
        "        input_type,\n",
        "        output_type,\n",
        "        M,\n",
        "        N,\n",
        "        K,\n",
        "        BLOCK_M,\n",
        "        BLOCK_N,\n",
        "        BLOCK_K,\n",
        "        num_stages,\n",
        "        use_warp_specialization,\n",
        "    )\n",
        "\n",
        "    # Launch the MLIR generated kernel\n",
        "    engine.invoke(kernelName, mem_a, mem_b, mem_c)\n",
        "\n",
        "    float_formatter = \"{:.2f}\".format\n",
        "    np.set_printoptions(formatter={\"float_kind\": float_formatter})\n",
        "\n",
        "    if print_results:\n",
        "        print(c)\n",
        "\n",
        "    # Verify the results\n",
        "    if not no_verify:\n",
        "        ref = a.astype(input_type) @ b.astype(input_type)\n",
        "        if print_results:\n",
        "            print(ref)\n",
        "        np.testing.assert_allclose(c, ref, rtol=5e-03, atol=1e-01)\n",
        "\n",
        "    print(\"PASS \")\n",
        "\n",
        "\n",
        "# Takes longer time to run\n",
        "def test_long():\n",
        "    for stages in range(1, 7):\n",
        "        for M in [128, 512, 1024, 4096, 8192]:\n",
        "            for N in [128, 512, 1024, 4096, 8192]:\n",
        "                for K in [64, 128, 512, 1024, 4096, 8192]:\n",
        "                    matmul(\n",
        "                        np.float16,\n",
        "                        np.float32,\n",
        "                        M,\n",
        "                        N,\n",
        "                        K,\n",
        "                        max_num_stages=stages,\n",
        "                        use_warp_specialization=False,\n",
        "                        no_verify=True,\n",
        "                    )\n",
        "                    matmul(\n",
        "                        np.float16,\n",
        "                        np.float32,\n",
        "                        M,\n",
        "                        N,\n",
        "                        K,\n",
        "                        max_num_stages=stages,\n",
        "                        use_warp_specialization=True,\n",
        "                    )\n",
        "\n",
        "\n",
        "def test_short():\n",
        "    for stages in [1, 3]:\n",
        "        for M in [128, 512]:\n",
        "            for N in [128]:\n",
        "                for K in [64, 256]:\n",
        "                    matmul(\n",
        "                        np.float16,\n",
        "                        np.float32,\n",
        "                        M,\n",
        "                        N,\n",
        "                        K,\n",
        "                        max_num_stages=stages,\n",
        "                        use_warp_specialization=False,\n",
        "                    )\n",
        "                    matmul(\n",
        "                        np.float16,\n",
        "                        np.float32,\n",
        "                        M,\n",
        "                        N,\n",
        "                        K,\n",
        "                        max_num_stages=stages,\n",
        "                        use_warp_specialization=True,\n",
        "                    )\n",
        "\n",
        "\n",
        "# CHECK: ===-- Running GEMM Multistage f32 += f16 * f16, Size 128x128x64, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Warp specialization f32 += f16 * f16, Size 128x128x64, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Multistage f32 += f16 * f16, Size 128x128x256, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Warp specialization f32 += f16 * f16, Size 128x128x256, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Multistage f32 += f16 * f16, Size 512x128x64, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Warp specialization f32 += f16 * f16, Size 512x128x64, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Multistage f32 += f16 * f16, Size 512x128x256, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Warp specialization f32 += f16 * f16, Size 512x128x256, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Multistage f32 += f16 * f16, Size 128x128x64, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Warp specialization f32 += f16 * f16, Size 128x128x64, Tile 128x128x64, stages 1 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Multistage f32 += f16 * f16, Size 128x128x256, Tile 128x128x64, stages 3 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Warp specialization f32 += f16 * f16, Size 128x128x256, Tile 128x128x64, stages 3 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Multistage f32 += f16 * f16, Size 512x128x64, Tile 128x128x64, stages 2 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Warp specialization f32 += f16 * f16, Size 512x128x64, Tile 128x128x64, stages 2 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Multistage f32 += f16 * f16, Size 512x128x256, Tile 128x128x64, stages 3 --===\n",
        "# CHECK: PASS\n",
        "# CHECK: ===-- Running GEMM Warp specialization f32 += f16 * f16, Size 512x128x256, Tile 128x128x64, stages 3 --===\n",
        "# CHECK: PASS\n",
        "\n",
        "test_short()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Command to run the script\n",
        "command = [\"python\", \"matmul.py\"]\n",
        "\n",
        "# Running the script and capturing the output\n",
        "process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "# Printing the standard output and standard error\n",
        "print(\"Standard Output:\\n\", process.stdout)\n",
        "print(\"Standard Error:\\n\", process.stderr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtrZL2Z_Qcfa",
        "outputId": "7a6b4f96-b96b-4f00-8c0e-4a19a710b0ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard Output:\n",
            " ===-- Running GEMM Multistage f32 += f16 * f16, Size 128x128x64, Tile 128x128x64, stages 1 --===\n",
            "\n",
            "Standard Error:\n",
            " 'cuTensorMapEncodeTiled( tensorMap, tensorDataType, tensorRank, globalAddress, globalDim, globalStrides, boxDim, elementStrides, interleave, swizzle, l2Promotion, oobFill)' failed with 'CUDA_ERROR_NOT_SUPPORTED'\n",
            "'cuTensorMapEncodeTiled( tensorMap, tensorDataType, tensorRank, globalAddress, globalDim, globalStrides, boxDim, elementStrides, interleave, swizzle, l2Promotion, oobFill)' failed with 'CUDA_ERROR_NOT_SUPPORTED'\n",
            "'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_NO_BINARY_FOR_GPU'\n",
            "'cuModuleGetFunction(&function, module, name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
            "'cuFuncSetAttribute( function, CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES, smem)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
            "'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
            "'cuModuleUnload(module)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Cuda/MLIR/python/matmul.py\", line 341, in <module>\n",
            "    test_short()\n",
            "  File \"/content/drive/MyDrive/Cuda/MLIR/python/matmul.py\", line 288, in test_short\n",
            "    matmul(\n",
            "  File \"/content/drive/MyDrive/Cuda/MLIR/python/matmul.py\", line 251, in matmul\n",
            "    np.testing.assert_allclose(c, ref, rtol=5e-03, atol=1e-01)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/testing/_private/utils.py\", line 1504, in assert_allclose\n",
            "    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/testing/_private/utils.py\", line 797, in assert_array_compare\n",
            "    raise AssertionError(msg)\n",
            "AssertionError: \n",
            "Not equal to tolerance rtol=0.005, atol=0.1\n",
            "\n",
            "Mismatched elements: 16217 / 16384 (99%)\n",
            "Max absolute difference: 36.78\n",
            "Max relative difference: 1.00\n",
            " x: array([[0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],\n",
            "       [0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],\n",
            "       [0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00],...\n",
            " y: array([[-0.35, -12.83, 7.42, ..., -5.81, -2.34, -14.92],\n",
            "       [-3.74, -0.15, 10.08, ..., -2.46, -3.21, 15.73],\n",
            "       [20.70, -12.27, 12.30, ..., -2.81, -3.14, -12.93],...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTET0wLJKBeF"
      },
      "source": [
        "### Driver code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uci6sLSnKBeG"
      },
      "outputs": [],
      "source": [
        "# Define the parameters for the matmul function\n",
        "M = 1024  # Number of rows in the first matrix\n",
        "N = 1024  # Number of columns in the second matrix\n",
        "K = 1024  # Number of columns in the first matrix / rows in the second matrix\n",
        "\n",
        "# Define the tile sizes\n",
        "BLOCK_M = 128\n",
        "BLOCK_N = 128\n",
        "BLOCK_K = 128\n",
        "\n",
        "# Define the data types for the input and output matrices\n",
        "ity = 'float32'\n",
        "oty = 'float32'\n",
        "\n",
        "# Define the number of stages\n",
        "max_num_stages = 3\n",
        "\n",
        "# Define the flags\n",
        "use_warp_specialization = True\n",
        "print_results = False\n",
        "no_verify = False\n",
        "saveIR = False\n",
        "\n",
        "# Call the matmul function\n",
        "matmul(M, N, K, BLOCK_M, BLOCK_N, BLOCK_K, ity, oty, max_num_stages, use_warp_specialization, print_results, no_verify, saveIR)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}