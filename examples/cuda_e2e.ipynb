{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Based on [transform-mma-sync-matmul-f16-f16-accum.mlir](https://github.com/llvm/llvm-project/blob/9cc2122bf5a81f7063c2a32b2cb78c8d615578a1/mlir/test/Integration/GPU/CUDA/TensorCore/sm80/transform-mma-sync-matmul-f16-f16-accum.mlir#L6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from readme\n",
    "\n",
    "```shell\n",
    "$ pip install mlir-python-bindings -f https://makslevental.github.io/wheels/\n",
    "```\n",
    "\n",
    "and then\n",
    "\n",
    "```shell\n",
    "$ pip install git+https://github.com/makslevental/mlir-python-extras\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "\u001b[31mERROR: Could not find a version that satisfies the requirement mlir_python_bindings==19.0.0.2024020206+cuda.374a600d (from versions: 19.0.0.2024022801+bcbce807, 19.0.0.2024022801+cuda.bcbce807, 19.0.0.2024022801+openmp.bcbce807, 19.0.0.2024022801+vulkan.bcbce807, 19.0.0.2024022901+0fe4b9da, 19.0.0.2024022901+cuda.0fe4b9da, 19.0.0.2024022901+openmp.0fe4b9da, 19.0.0.2024022901+vulkan.0fe4b9da, 19.0.0.2024030101+7ceb74f5, 19.0.0.2024030101+cuda.7ceb74f5, 19.0.0.2024030101+openmp.7ceb74f5, 19.0.0.2024030101+vulkan.7ceb74f5, 19.0.0.2024030217+b901b0d3, 19.0.0.2024030217+cuda.b901b0d3, 19.0.0.2024030217+openmp.b901b0d3, 19.0.0.2024030217+vulkan.b901b0d3, 19.0.0.2024030301+4dd9c2ed, 19.0.0.2024030301+cuda.4dd9c2ed, 19.0.0.2024030301+openmp.4dd9c2ed, 19.0.0.2024030301+vulkan.4dd9c2ed, 19.0.0.2024030401+5f058aa2, 19.0.0.2024030401+cuda.5f058aa2, 19.0.0.2024030401+openmp.5f058aa2, 19.0.0.2024030401+vulkan.5f058aa2, 19.0.0.2024030501+ccf0c8da, 19.0.0.2024030501+cuda.ccf0c8da, 19.0.0.2024030501+openmp.ccf0c8da, 19.0.0.2024030501+vulkan.ccf0c8da, 19.0.0.2024030601+11f74cd4, 19.0.0.2024030601+cuda.11f74cd4, 19.0.0.2024030601+openmp.11f74cd4, 19.0.0.2024030601+vulkan.11f74cd4, 19.0.0.2024030701+318bff68, 19.0.0.2024030701+cuda.318bff68, 19.0.0.2024030701+openmp.318bff68, 19.0.0.2024030701+vulkan.318bff68, 19.0.0.2024030801+cuda.e7a22e72, 19.0.0.2024030801+e7a22e72, 19.0.0.2024030801+openmp.e7a22e72, 19.0.0.2024030801+vulkan.e7a22e72, 19.0.0.2024030901+6b270358, 19.0.0.2024030901+cuda.6b270358, 19.0.0.2024030901+openmp.6b270358, 19.0.0.2024030901+vulkan.6b270358, 19.0.0.2024031001+15e94781, 19.0.0.2024031001+cuda.15e94781, 19.0.0.2024031001+openmp.15e94781, 19.0.0.2024031001+vulkan.15e94781, 19.0.0.2024031101+cuda.edd4c6c6, 19.0.0.2024031101+edd4c6c6, 19.0.0.2024031101+openmp.edd4c6c6, 19.0.0.2024031101+vulkan.edd4c6c6, 19.0.0.2024031203+cuda.e4a54675, 19.0.0.2024031203+e4a54675, 19.0.0.2024031203+openmp.e4a54675, 19.0.0.2024031203+vulkan.e4a54675, 19.0.0.2024031217+93503aaf, 19.0.0.2024031217+cuda.93503aaf, 19.0.0.2024031217+openmp.93503aaf, 19.0.0.2024031217+vulkan.93503aaf, 19.0.0.2024031301+9d6c43b4, 19.0.0.2024031301+cuda.9d6c43b4, 19.0.0.2024031301+openmp.9d6c43b4, 19.0.0.2024031301+vulkan.9d6c43b4, 19.0.0.2024031401+02cadde5, 19.0.0.2024031401+cuda.02cadde5, 19.0.0.2024031401+openmp.02cadde5, 19.0.0.2024031401+vulkan.02cadde5, 19.0.0.2024031501+cuda.e4f71959, 19.0.0.2024031501+e4f71959, 19.0.0.2024031501+openmp.e4f71959, 19.0.0.2024031501+vulkan.e4f71959, 19.0.0.2024031601+8386a388, 19.0.0.2024031601+cuda.8386a388, 19.0.0.2024031601+openmp.8386a388, 19.0.0.2024031601+vulkan.8386a388, 19.0.0.2024031701+8f878c50, 19.0.0.2024031701+cuda.8f878c50, 19.0.0.2024031701+openmp.8f878c50, 19.0.0.2024031701+vulkan.8f878c50, 19.0.0.2024031801+6cc8d54a, 19.0.0.2024031801+cuda.6cc8d54a, 19.0.0.2024031801+openmp.6cc8d54a, 19.0.0.2024031801+vulkan.6cc8d54a, 19.0.0.2024031901+a6296214, 19.0.0.2024031901+cuda.a6296214, 19.0.0.2024031901+openmp.a6296214, 19.0.0.2024031901+vulkan.a6296214, 19.0.0.2024032001+09db84cc, 19.0.0.2024032001+cuda.09db84cc, 19.0.0.2024032001+openmp.09db84cc, 19.0.0.2024032001+vulkan.09db84cc, 19.0.0.2024032101+631248dc, 19.0.0.2024032101+cuda.631248dc, 19.0.0.2024032101+openmp.631248dc, 19.0.0.2024032101+vulkan.631248dc, 19.0.0.2024032201+718fbbef, 19.0.0.2024032201+cuda.718fbbef, 19.0.0.2024032201+openmp.718fbbef, 19.0.0.2024032201+vulkan.718fbbef, 19.0.0.2024032301+2f6b1b4b, 19.0.0.2024032301+cuda.2f6b1b4b, 19.0.0.2024032301+openmp.2f6b1b4b, 19.0.0.2024032301+vulkan.2f6b1b4b, 19.0.0.2024032401+8e698a1d, 19.0.0.2024032401+cuda.8e698a1d, 19.0.0.2024032401+openmp.8e698a1d, 19.0.0.2024032401+vulkan.8e698a1d, 19.0.0.2024032501+cceedc93, 19.0.0.2024032501+cuda.cceedc93, 19.0.0.2024032601+cuda.ce73b167, 19.0.0.2024032601+openmp.ce73b167, 19.0.0.2024032601+vulkan.ce73b167, 19.0.0.2024032701+4720e383, 19.0.0.2024032701+cuda.4720e383, 19.0.0.2024032701+openmp.4720e383, 19.0.0.2024032701+vulkan.4720e383, 19.0.0.2024032801+1095f71b, 19.0.0.2024032801+cuda.1095f71b, 19.0.0.2024032801+openmp.1095f71b, 19.0.0.2024032801+vulkan.1095f71b, 19.0.0.2024032901+39e81374, 19.0.0.2024032901+cuda.39e81374, 19.0.0.2024032901+openmp.39e81374, 19.0.0.2024032901+vulkan.39e81374)\u001b[0m\u001b[31m\n",
    "\u001b[0m\u001b[31mERROR: No matching distribution found for mlir_python_bindings==19.0.0.2024020206+cuda.374a600d\u001b[0m\u001b[31m\n",
    "\u001b[0m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install mlir_python_bindings==19.0.0.2024032901+cuda.39e81374 -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032801+cuda.1095f71b -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032701+cuda.4720e383 -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032601+cuda.ce73b167 -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032501+cuda.cceedc93 -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032401+cuda.8e698a1d -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032301+cuda.2f6b1b4b -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032201+cuda.718fbbef -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032101+cuda.631248dc -f https://makslevental.github.io/wheels/\n",
    "pip install mlir_python_bindings==19.0.0.2024032001+cuda.09db84cc -f https://makslevental.github.io/wheels/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.587406187Z",
     "start_time": "2024-02-02T23:42:30.667121274Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xh-QUDWiX-FD",
    "outputId": "6865a63a-daa4-4610-e33a-721d37c0211f"
   },
   "outputs": [],
   "source": [
    "# install cuda from above\n",
    "\n",
    "#! pip install -q git+https://github.com/makslevental/mlir-python-extras.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSATAYhg7pSZ"
   },
   "source": [
    "# Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.631298039Z",
     "start_time": "2024-02-02T23:42:40.630713260Z"
    },
    "id": "_R-_0M5ZYO8p"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import mlir.extras.types as T\n",
    "from mlir.dialects import builtin\n",
    "from mlir.dialects.transform import * #any_op_t\n",
    "from mlir.dialects.transform.extras import * #named_sequence\n",
    "from mlir.dialects.transform.structured import MatchInterfaceEnum\n",
    "from mlir.ir import StringAttr, UnitAttr\n",
    "\n",
    "from mlir import _mlir_libs\n",
    "from mlir.extras.ast.canonicalize import canonicalize\n",
    "from mlir.extras.context import RAIIMLIRContext, ExplicitlyManagedModule\n",
    "from mlir.extras.dialects.ext import arith, memref, scf, gpu\n",
    "from mlir.extras.dialects.ext import linalg\n",
    "from mlir.extras.dialects.ext import transform\n",
    "from mlir.extras.dialects.ext.func import func\n",
    "from mlir.extras.runtime.passes import Pipeline, run_pipeline\n",
    "from mlir.extras.runtime.refbackend import LLVMJITBackend\n",
    "from mlir.extras.util import find_ops\n",
    "\n",
    "CUDA_RUNTIME_LIB_PATH = Path(_mlir_libs.__file__).parent / f\"libmlir_cuda_runtime.so\"\n",
    "assert CUDA_RUNTIME_LIB_PATH.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-JTcrjo7tNK"
   },
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.631765526Z",
     "start_time": "2024-02-02T23:42:40.630962853Z"
    },
    "id": "AGpWj9BzZLC_"
   },
   "outputs": [],
   "source": [
    "ctx = RAIIMLIRContext()\n",
    "module = ExplicitlyManagedModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGcDtgkv71YB"
   },
   "source": [
    "# Kernel and helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.728400651Z",
     "start_time": "2024-02-02T23:42:40.631097458Z"
    },
    "id": "7oQk4xJd72FI"
   },
   "outputs": [],
   "source": [
    "range_ = scf.range_\n",
    "\n",
    "M, K, N = 16, 16, 8\n",
    "\n",
    "# forward reference...\n",
    "# TODO(max): figure out closures...\n",
    "printMemrefF32_ = []\n",
    "\n",
    "\n",
    "@func\n",
    "def compute_linspace_val(ridx: T.index(), cidx: T.index(), stride_cidx: T.index()):\n",
    "    r = arith.index_cast(ridx, to=T.i32())\n",
    "    c = arith.index_cast(cidx, to=T.i32())\n",
    "    stride_c = arith.index_cast(stride_cidx, to=T.i32())\n",
    "    v2 = r * stride_c\n",
    "    v3 = c + v2\n",
    "    v4 = arith.sitofp(T.f16(), v3)\n",
    "    factor = arith.constant(64.0, T.f16())\n",
    "    v5 = arith.divf(v4, factor)\n",
    "    return v5\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_lhs_as_memref_32(lhs: T.memref(M, K, T.f16())):\n",
    "    M = memref.dim(lhs, 0)\n",
    "    K = memref.dim(lhs, 1)\n",
    "    tmp_alloc = memref.alloc(M, K, T.f32())\n",
    "    for m in range_(0, M):\n",
    "        for k in range_(0, K):\n",
    "            f16 = lhs[m, k]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[m, k] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_rhs_as_memref_32(rhs: T.memref(K, N, T.f16())):\n",
    "    K = memref.dim(rhs, 0)\n",
    "    N = memref.dim(rhs, 1)\n",
    "    tmp_alloc = memref.alloc(K, N, T.f32())\n",
    "    for k in range_(0, K):\n",
    "        for n in range_(0, N):\n",
    "            f16 = rhs[k, n]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[k, n] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def print_res_as_memref_32(res: T.memref(M, N, T.f16())):\n",
    "    c0 = arith.constant(0, index=True)\n",
    "    c1 = arith.constant(1, index=True)\n",
    "    M = memref.dim(res, c0)\n",
    "    N = memref.dim(res, c1)\n",
    "    tmp_alloc = memref.alloc(M, N, T.f32())\n",
    "    for m in range_(0, M):\n",
    "        for n in range_(0, N):\n",
    "            f16 = res[m, n]\n",
    "            f32 = arith.extf(T.f32(), f16)\n",
    "            tmp_alloc[m, n] = f32\n",
    "\n",
    "    casted = memref.cast(T.memref(T.f32()), tmp_alloc)\n",
    "    printMemrefF32_[0](casted)\n",
    "    memref.dealloc(tmp_alloc)\n",
    "\n",
    "\n",
    "@func\n",
    "@canonicalize(using=scf.canonicalizer)\n",
    "def main():\n",
    "    lhs = memref.alloc(M, K, T.f16())\n",
    "    rhs = memref.alloc(K, N, T.f16())\n",
    "    res = memref.alloc(M, N, T.f16())\n",
    "\n",
    "    M_ = memref.dim(res, 0)\n",
    "    N_ = memref.dim(res, 1)\n",
    "    K_ = memref.dim(lhs, 1)\n",
    "\n",
    "    _f1 = arith.constant(1.0e00, T.f16())\n",
    "    _f0 = arith.constant(0.0e00, T.f16())\n",
    "    _c32 = arith.constant(32, T.index())\n",
    "\n",
    "    # Initialize the lhs matrix with a linspace function.\n",
    "    for r in range_(0, M_):\n",
    "        for c in range_(0, K_):\n",
    "            idx = compute_linspace_val(r, c, K_)\n",
    "            lhs[r, c] = idx\n",
    "\n",
    "    # Initialize the rhs matrix with a linspace function.\n",
    "    for r in range_(0, K_):\n",
    "        for c in range_(0, N_):\n",
    "            idx = compute_linspace_val(r, c, N_)\n",
    "            rhs[r, c] = idx\n",
    "\n",
    "    # Initialize the res matrix with a linspace function.\n",
    "    for r in range_(0, M_):\n",
    "        for c in range_(0, N_):\n",
    "            idx = compute_linspace_val(r, c, N_)\n",
    "            res[r, c] = idx\n",
    "\n",
    "    ulhs = memref.cast(T.memref(T.f16()), lhs)\n",
    "    urhs = memref.cast(T.memref(T.f16()), rhs)\n",
    "    ures = memref.cast(T.memref(T.f16()), res)\n",
    "    gpu.host_register(ulhs)\n",
    "    gpu.host_register(urhs)\n",
    "    gpu.host_register(ures)\n",
    "\n",
    "    print_lhs_as_memref_32(lhs)\n",
    "    print_rhs_as_memref_32(rhs)\n",
    "\n",
    "    @gpu.launch(grid_size=[1, 1, 1], block_size=[32, 1, 1])\n",
    "    def kernel(bx, by, bz, tx, ty, tz, *grid_block_sizes):\n",
    "        linalg.matmul(lhs, rhs, res)\n",
    "\n",
    "    print_res_as_memref_32(res)\n",
    "\n",
    "\n",
    "@builtin.module(attrs={\"transform.target_tag\": StringAttr.get(\"payload\")})\n",
    "def payload():\n",
    "    compute_linspace_val.emit()\n",
    "\n",
    "    @func\n",
    "    def printMemrefF32(x: T.memref(T.f32())):\n",
    "        ...\n",
    "\n",
    "    printMemrefF32_.append(printMemrefF32)\n",
    "\n",
    "    print_lhs_as_memref_32.emit()\n",
    "    print_rhs_as_memref_32.emit()\n",
    "    print_res_as_memref_32.emit()\n",
    "    main.emit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0vJZrpR74KB"
   },
   "source": [
    "# Transform schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.733574415Z",
     "start_time": "2024-02-02T23:42:40.731419468Z"
    },
    "id": "EaBgGTIz72ci"
   },
   "outputs": [],
   "source": [
    "@builtin.module(attrs={\"transform.with_named_sequence\": UnitAttr.get()})\n",
    "def mod_transform():\n",
    "    @named_sequence(\n",
    "        \"main\", [any_op_t()], [], arg_attrs=[{\"transform.readonly\": UnitAttr.get()}]\n",
    "    )\n",
    "    def main(module: any_op_t()):\n",
    "        matmul = transform.match(module, [\"linalg.matmul\"])\n",
    "        transform.nvgpu.rewrite_matmul_as_mma_sync(matmul)\n",
    "        # clean up to simplify test below...\n",
    "        all_loops = transform.match(\n",
    "            module, interface=MatchInterfaceEnum.LoopLikeInterface\n",
    "        )\n",
    "        transform.apply_licm(all_loops)\n",
    "        transform.apply_cse(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADbabroS8ND2"
   },
   "source": [
    "# \"Finish\" the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.775039674Z",
     "start_time": "2024-02-02T23:42:40.733656110Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUOsYXaW8QKC",
    "outputId": "f8592229-1d9b-4c52-9133-30fd52c2716d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module {\n",
      "  module attributes {transform.target_tag = \"payload\"} {\n",
      "    func.func @compute_linspace_val(%arg0: index, %arg1: index, %arg2: index) -> f16 {\n",
      "      %0 = arith.index_cast %arg0 : index to i32\n",
      "      %1 = arith.index_cast %arg1 : index to i32\n",
      "      %2 = arith.index_cast %arg2 : index to i32\n",
      "      %3 = arith.muli %0, %2 : i32\n",
      "      %4 = arith.addi %1, %3 : i32\n",
      "      %5 = arith.sitofp %4 : i32 to f16\n",
      "      %cst = arith.constant 6.400000e+01 : f16\n",
      "      %6 = arith.divf %5, %cst : f16\n",
      "      return %6 : f16\n",
      "    }\n",
      "    func.func private @printMemrefF32(memref<*xf32>)\n",
      "    func.func @print_lhs_as_memref_32(%arg0: memref<16x16xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x16xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x16xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      %c0_1 = arith.constant 0 : index\n",
      "      %c1_2 = arith.constant 1 : index\n",
      "      scf.for %arg1 = %c0_1 to %dim step %c1_2 {\n",
      "        %c0_3 = arith.constant 0 : index\n",
      "        %c1_4 = arith.constant 1 : index\n",
      "        scf.for %arg2 = %c0_3 to %dim_0 step %c1_4 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x16xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @print_rhs_as_memref_32(%arg0: memref<16x8xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x8xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x8xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      %c0_1 = arith.constant 0 : index\n",
      "      %c1_2 = arith.constant 1 : index\n",
      "      scf.for %arg1 = %c0_1 to %dim step %c1_2 {\n",
      "        %c0_3 = arith.constant 0 : index\n",
      "        %c1_4 = arith.constant 1 : index\n",
      "        scf.for %arg2 = %c0_3 to %dim_0 step %c1_4 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x8xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @print_res_as_memref_32(%arg0: memref<16x8xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x8xf16>\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x8xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      %c0_1 = arith.constant 0 : index\n",
      "      %c1_2 = arith.constant 1 : index\n",
      "      scf.for %arg1 = %c0_1 to %dim step %c1_2 {\n",
      "        %c0_3 = arith.constant 0 : index\n",
      "        %c1_4 = arith.constant 1 : index\n",
      "        scf.for %arg2 = %c0_3 to %dim_0 step %c1_4 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x8xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @main() {\n",
      "      %alloc = memref.alloc() : memref<16x16xf16>\n",
      "      %alloc_0 = memref.alloc() : memref<16x8xf16>\n",
      "      %alloc_1 = memref.alloc() : memref<16x8xf16>\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %alloc_1, %c0 : memref<16x8xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_2 = memref.dim %alloc_1, %c1 : memref<16x8xf16>\n",
      "      %c1_3 = arith.constant 1 : index\n",
      "      %dim_4 = memref.dim %alloc, %c1_3 : memref<16x16xf16>\n",
      "      %cst = arith.constant 1.000000e+00 : f16\n",
      "      %cst_5 = arith.constant 0.000000e+00 : f16\n",
      "      %c32 = arith.constant 32 : index\n",
      "      %c0_6 = arith.constant 0 : index\n",
      "      %c1_7 = arith.constant 1 : index\n",
      "      scf.for %arg0 = %c0_6 to %dim step %c1_7 {\n",
      "        %c0_20 = arith.constant 0 : index\n",
      "        %c1_21 = arith.constant 1 : index\n",
      "        scf.for %arg1 = %c0_20 to %dim_4 step %c1_21 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_4) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc[%arg0, %arg1] : memref<16x16xf16>\n",
      "        }\n",
      "      }\n",
      "      %c0_8 = arith.constant 0 : index\n",
      "      %c1_9 = arith.constant 1 : index\n",
      "      scf.for %arg0 = %c0_8 to %dim_4 step %c1_9 {\n",
      "        %c0_20 = arith.constant 0 : index\n",
      "        %c1_21 = arith.constant 1 : index\n",
      "        scf.for %arg1 = %c0_20 to %dim_2 step %c1_21 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_2) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc_0[%arg0, %arg1] : memref<16x8xf16>\n",
      "        }\n",
      "      }\n",
      "      %c0_10 = arith.constant 0 : index\n",
      "      %c1_11 = arith.constant 1 : index\n",
      "      scf.for %arg0 = %c0_10 to %dim step %c1_11 {\n",
      "        %c0_20 = arith.constant 0 : index\n",
      "        %c1_21 = arith.constant 1 : index\n",
      "        scf.for %arg1 = %c0_20 to %dim_2 step %c1_21 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_2) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc_1[%arg0, %arg1] : memref<16x8xf16>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<16x16xf16> to memref<*xf16>\n",
      "      %cast_12 = memref.cast %alloc_0 : memref<16x8xf16> to memref<*xf16>\n",
      "      %cast_13 = memref.cast %alloc_1 : memref<16x8xf16> to memref<*xf16>\n",
      "      gpu.host_register %cast : memref<*xf16>\n",
      "      gpu.host_register %cast_12 : memref<*xf16>\n",
      "      gpu.host_register %cast_13 : memref<*xf16>\n",
      "      call @print_lhs_as_memref_32(%alloc) : (memref<16x16xf16>) -> ()\n",
      "      call @print_rhs_as_memref_32(%alloc_0) : (memref<16x8xf16>) -> ()\n",
      "      %c1_14 = arith.constant 1 : index\n",
      "      %c1_15 = arith.constant 1 : index\n",
      "      %c1_16 = arith.constant 1 : index\n",
      "      %c32_17 = arith.constant 32 : index\n",
      "      %c1_18 = arith.constant 1 : index\n",
      "      %c1_19 = arith.constant 1 : index\n",
      "      gpu.launch blocks(%arg0, %arg1, %arg2) in (%arg6 = %c1_14, %arg7 = %c1_15, %arg8 = %c1_16) threads(%arg3, %arg4, %arg5) in (%arg9 = %c32_17, %arg10 = %c1_18, %arg11 = %c1_19) {\n",
      "        linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%alloc, %alloc_0 : memref<16x16xf16>, memref<16x8xf16>) outs(%alloc_1 : memref<16x8xf16>)\n",
      "        gpu.terminator\n",
      "      }\n",
      "      call @print_res_as_memref_32(%alloc_1) : (memref<16x8xf16>) -> ()\n",
      "      return\n",
      "    }\n",
      "  }\n",
      "  module attributes {transform.with_named_sequence} {\n",
      "    transform.named_sequence @main(%arg0: !transform.any_op {transform.readonly}) {\n",
      "      %0 = transform.structured.match ops{[\"linalg.matmul\"]} in %arg0 : (!transform.any_op) -> !transform.any_op\n",
      "      transform.nvgpu.rewrite_matmul_as_mma_sync %0 : (!transform.any_op) -> ()\n",
      "      %1 = transform.structured.match interface{LoopLikeInterface} in %arg0 : (!transform.any_op) -> !transform.any_op\n",
      "      transform.apply_licm to %1 : !transform.any_op\n",
      "      transform.apply_cse to %arg0 : !transform.any_op\n",
      "      transform.yield \n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "module = module.finish()\n",
    "print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xN5kNvZ8Tyf"
   },
   "source": [
    "# Execute the transform schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.775757596Z",
     "start_time": "2024-02-02T23:42:40.774788838Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLwQLPD98Q4d",
    "outputId": "ecfa6c9a-15eb-40c7-df29-f43fcac02fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#map = affine_map<(d0) -> (d0 floordiv 4)>\n",
      "#map1 = affine_map<(d0) -> (d0 * 2 - (d0 floordiv 4) * 8)>\n",
      "#map2 = affine_map<(d0) -> (d0 * 2 - (d0 floordiv 4) * 8 + 1)>\n",
      "#map3 = affine_map<(d0) -> (d0 floordiv 4 + 8)>\n",
      "#map4 = affine_map<(d0) -> (d0 * 2 - (d0 floordiv 4) * 8 + 8)>\n",
      "#map5 = affine_map<(d0) -> (d0 * 2 - (d0 floordiv 4) * 8 + 9)>\n",
      "module {\n",
      "  module attributes {transform.target_tag = \"payload\"} {\n",
      "    func.func @compute_linspace_val(%arg0: index, %arg1: index, %arg2: index) -> f16 {\n",
      "      %0 = arith.index_cast %arg0 : index to i32\n",
      "      %1 = arith.index_cast %arg1 : index to i32\n",
      "      %2 = arith.index_cast %arg2 : index to i32\n",
      "      %3 = arith.muli %0, %2 : i32\n",
      "      %4 = arith.addi %1, %3 : i32\n",
      "      %5 = arith.sitofp %4 : i32 to f16\n",
      "      %cst = arith.constant 6.400000e+01 : f16\n",
      "      %6 = arith.divf %5, %cst : f16\n",
      "      return %6 : f16\n",
      "    }\n",
      "    func.func private @printMemrefF32(memref<*xf32>)\n",
      "    func.func @print_lhs_as_memref_32(%arg0: memref<16x16xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x16xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x16xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      scf.for %arg1 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg2 = %c0 to %dim_0 step %c1 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x16xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @print_rhs_as_memref_32(%arg0: memref<16x8xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x8xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x8xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      scf.for %arg1 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg2 = %c0 to %dim_0 step %c1 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x8xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @print_res_as_memref_32(%arg0: memref<16x8xf16>) {\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim = memref.dim %arg0, %c0 : memref<16x8xf16>\n",
      "      %dim_0 = memref.dim %arg0, %c1 : memref<16x8xf16>\n",
      "      %alloc = memref.alloc(%dim, %dim_0) : memref<?x?xf32>\n",
      "      scf.for %arg1 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg2 = %c0 to %dim_0 step %c1 {\n",
      "          %0 = memref.load %arg0[%arg1, %arg2] : memref<16x8xf16>\n",
      "          %1 = arith.extf %0 : f16 to f32\n",
      "          memref.store %1, %alloc[%arg1, %arg2] : memref<?x?xf32>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<?x?xf32> to memref<*xf32>\n",
      "      call @printMemrefF32(%cast) : (memref<*xf32>) -> ()\n",
      "      memref.dealloc %alloc : memref<?x?xf32>\n",
      "      return\n",
      "    }\n",
      "    func.func @main() {\n",
      "      %alloc = memref.alloc() : memref<16x16xf16>\n",
      "      %alloc_0 = memref.alloc() : memref<16x8xf16>\n",
      "      %alloc_1 = memref.alloc() : memref<16x8xf16>\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %dim = memref.dim %alloc_1, %c0 : memref<16x8xf16>\n",
      "      %c1 = arith.constant 1 : index\n",
      "      %dim_2 = memref.dim %alloc_1, %c1 : memref<16x8xf16>\n",
      "      %dim_3 = memref.dim %alloc, %c1 : memref<16x16xf16>\n",
      "      scf.for %arg0 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg1 = %c0 to %dim_3 step %c1 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_3) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc[%arg0, %arg1] : memref<16x16xf16>\n",
      "        }\n",
      "      }\n",
      "      scf.for %arg0 = %c0 to %dim_3 step %c1 {\n",
      "        scf.for %arg1 = %c0 to %dim_2 step %c1 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_2) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc_0[%arg0, %arg1] : memref<16x8xf16>\n",
      "        }\n",
      "      }\n",
      "      scf.for %arg0 = %c0 to %dim step %c1 {\n",
      "        scf.for %arg1 = %c0 to %dim_2 step %c1 {\n",
      "          %0 = func.call @compute_linspace_val(%arg0, %arg1, %dim_2) : (index, index, index) -> f16\n",
      "          memref.store %0, %alloc_1[%arg0, %arg1] : memref<16x8xf16>\n",
      "        }\n",
      "      }\n",
      "      %cast = memref.cast %alloc : memref<16x16xf16> to memref<*xf16>\n",
      "      %cast_4 = memref.cast %alloc_0 : memref<16x8xf16> to memref<*xf16>\n",
      "      %cast_5 = memref.cast %alloc_1 : memref<16x8xf16> to memref<*xf16>\n",
      "      gpu.host_register %cast : memref<*xf16>\n",
      "      gpu.host_register %cast_4 : memref<*xf16>\n",
      "      gpu.host_register %cast_5 : memref<*xf16>\n",
      "      call @print_lhs_as_memref_32(%alloc) : (memref<16x16xf16>) -> ()\n",
      "      call @print_rhs_as_memref_32(%alloc_0) : (memref<16x8xf16>) -> ()\n",
      "      %c32 = arith.constant 32 : index\n",
      "      gpu.launch blocks(%arg0, %arg1, %arg2) in (%arg6 = %c1, %arg7 = %c1, %arg8 = %c1) threads(%arg3, %arg4, %arg5) in (%arg9 = %c32, %arg10 = %c1, %arg11 = %c1) {\n",
      "        %thread_id_x = gpu.thread_id  x\n",
      "        %0 = affine.apply #map(%thread_id_x)\n",
      "        %1 = affine.apply #map1(%thread_id_x)\n",
      "        %2 = memref.load %alloc[%0, %1] : memref<16x16xf16>\n",
      "        %3 = affine.apply #map2(%thread_id_x)\n",
      "        %4 = memref.load %alloc[%0, %3] : memref<16x16xf16>\n",
      "        %5 = affine.apply #map3(%thread_id_x)\n",
      "        %6 = memref.load %alloc[%5, %1] : memref<16x16xf16>\n",
      "        %7 = memref.load %alloc[%5, %3] : memref<16x16xf16>\n",
      "        %8 = affine.apply #map4(%thread_id_x)\n",
      "        %9 = memref.load %alloc[%0, %8] : memref<16x16xf16>\n",
      "        %10 = affine.apply #map5(%thread_id_x)\n",
      "        %11 = memref.load %alloc[%0, %10] : memref<16x16xf16>\n",
      "        %12 = memref.load %alloc[%5, %8] : memref<16x16xf16>\n",
      "        %13 = memref.load %alloc[%5, %10] : memref<16x16xf16>\n",
      "        %14 = vector.splat %2 : vector<4x2xf16>\n",
      "        %15 = vector.insert %2, %14 [0, 0] : f16 into vector<4x2xf16>\n",
      "        %16 = vector.insert %4, %15 [0, 1] : f16 into vector<4x2xf16>\n",
      "        %17 = vector.insert %6, %16 [1, 0] : f16 into vector<4x2xf16>\n",
      "        %18 = vector.insert %7, %17 [1, 1] : f16 into vector<4x2xf16>\n",
      "        %19 = vector.insert %9, %18 [2, 0] : f16 into vector<4x2xf16>\n",
      "        %20 = vector.insert %11, %19 [2, 1] : f16 into vector<4x2xf16>\n",
      "        %21 = vector.insert %12, %20 [3, 0] : f16 into vector<4x2xf16>\n",
      "        %22 = vector.insert %13, %21 [3, 1] : f16 into vector<4x2xf16>\n",
      "        %23 = memref.load %alloc_0[%1, %0] : memref<16x8xf16>\n",
      "        %24 = memref.load %alloc_0[%3, %0] : memref<16x8xf16>\n",
      "        %25 = memref.load %alloc_0[%8, %0] : memref<16x8xf16>\n",
      "        %26 = memref.load %alloc_0[%10, %0] : memref<16x8xf16>\n",
      "        %27 = vector.splat %23 : vector<2x2xf16>\n",
      "        %28 = vector.insert %23, %27 [0, 0] : f16 into vector<2x2xf16>\n",
      "        %29 = vector.insert %24, %28 [0, 1] : f16 into vector<2x2xf16>\n",
      "        %30 = vector.insert %25, %29 [1, 0] : f16 into vector<2x2xf16>\n",
      "        %31 = vector.insert %26, %30 [1, 1] : f16 into vector<2x2xf16>\n",
      "        %32 = memref.load %alloc_1[%0, %1] : memref<16x8xf16>\n",
      "        %33 = memref.load %alloc_1[%0, %3] : memref<16x8xf16>\n",
      "        %34 = memref.load %alloc_1[%5, %1] : memref<16x8xf16>\n",
      "        %35 = memref.load %alloc_1[%5, %3] : memref<16x8xf16>\n",
      "        %36 = vector.splat %32 : vector<2x2xf16>\n",
      "        %37 = vector.insert %32, %36 [0, 0] : f16 into vector<2x2xf16>\n",
      "        %38 = vector.insert %33, %37 [0, 1] : f16 into vector<2x2xf16>\n",
      "        %39 = vector.insert %34, %38 [1, 0] : f16 into vector<2x2xf16>\n",
      "        %40 = vector.insert %35, %39 [1, 1] : f16 into vector<2x2xf16>\n",
      "        %41 = nvgpu.mma.sync(%22, %31, %40) {mmaShape = [16, 8, 16]} : (vector<4x2xf16>, vector<2x2xf16>, vector<2x2xf16>) -> vector<2x2xf16>\n",
      "        %42 = vector.extract %41[0, 0] : f16 from vector<2x2xf16>\n",
      "        %43 = vector.extract %41[0, 1] : f16 from vector<2x2xf16>\n",
      "        %44 = vector.extract %41[1, 0] : f16 from vector<2x2xf16>\n",
      "        %45 = vector.extract %41[1, 1] : f16 from vector<2x2xf16>\n",
      "        memref.store %42, %alloc_1[%0, %1] : memref<16x8xf16>\n",
      "        memref.store %43, %alloc_1[%0, %3] : memref<16x8xf16>\n",
      "        memref.store %44, %alloc_1[%5, %1] : memref<16x8xf16>\n",
      "        memref.store %45, %alloc_1[%5, %3] : memref<16x8xf16>\n",
      "        gpu.terminator\n",
      "      }\n",
      "      call @print_res_as_memref_32(%alloc_1) : (memref<16x8xf16>) -> ()\n",
      "      return\n",
      "    }\n",
      "  }\n",
      "  module attributes {transform.with_named_sequence} {\n",
      "    transform.named_sequence @main(%arg0: !transform.any_op {transform.readonly}) {\n",
      "      %0 = transform.structured.match ops{[\"linalg.matmul\"]} in %arg0 : (!transform.any_op) -> !transform.any_op\n",
      "      transform.nvgpu.rewrite_matmul_as_mma_sync %0 : (!transform.any_op) -> ()\n",
      "      %1 = transform.structured.match interface{LoopLikeInterface} in %arg0 : (!transform.any_op) -> !transform.any_op\n",
      "      transform.apply_licm to %1 : !transform.any_op\n",
      "      transform.apply_cse to %arg0 : !transform.any_op\n",
      "      transform.yield \n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = run_pipeline(\n",
    "    module,\n",
    "    Pipeline().transform_interpreter(\n",
    "        entry_point=\"main\", debug_payload_root_tag=\"payload\"\n",
    "    ),\n",
    ")\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_NURglF8ZZW"
   },
   "source": [
    "# Lower to NVVM (and LLVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.830771046Z",
     "start_time": "2024-02-02T23:42:40.775057708Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IoWjgc48bcn",
    "outputId": "39550464-fd37-4e6d-a257-e803b746d8de"
   },
   "outputs": [
    {
     "ename": "MlirCompilerError",
     "evalue": "Lowering IR failed with the following diagnostics:\n\n********************************************************************************\nFailure while executing pass pipeline:\nerror: unknown: `ptxas` invocation failed. Log:\nptxas /tmp/mlir-main_kernel-nvptx64-nvidia-cuda-sm_80-12fe81.ptx, line 5; fatal   : Unsupported .version 7.6; current version is '7.5'\nptxas fatal   : Ptx assembly aborted due to errors\n\nerror: unknown: An error happened while serializing the module.\nnote: unknown: see current operation: \n\"gpu.module\"() <{targets = [#nvvm.target<chip = \"sm_80\", features = \"+ptx76\">]}> ({\n\"llvm.func\"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<void (ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64)>, linkage = #llvm.linkage<external>, sym_name = \"main_kernel\", visibility_ = 0 : i64}> ({\n^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64):\n%0 = \"llvm.mlir.constant\"() <{value = 1 : i64}> : () -> i64\n%1 = \"llvm.mlir.constant\"() <{value = 0 : i64}> : () -> i64\n%2 = \"llvm.mlir.constant\"() <{value = 0 : i32}> : () -> i32\n%3 = \"llvm.mlir.constant\"() <{value = 16 : index}> : () -> i64\n%4 = \"llvm.mlir.constant\"() <{value = 4 : index}> : () -> i64\n%5 = \"llvm.mlir.constant\"() <{value = 0 : index}> : () -> i64\n%6 = \"llvm.mlir.constant\"() <{value = -1 : index}> : () -> i64\n%7 = \"llvm.mlir.constant\"() <{value = 2 : index}> : () -> i64\n%8 = \"llvm.mlir.constant\"() <{value = -8 : index}> : () -> i64\n%9 = \"llvm.mlir.constant\"() <{value = 1 : index}> : () -> i64\n%10 = \"llvm.mlir.constant\"() <{value = 8 : index}> : () -> i64\n%11 = \"llvm.mlir.constant\"() <{value = 9 : index}> : () -> i64\n\"llvm.br\"()[^bb1] : () -> ()\n^bb1:  // pred: ^bb0\n%12 = \"nvvm.read.ptx.sreg.tid.x\"() : () -> i32\n%13 = \"llvm.sext\"(%12) : (i32) -> i64\n%14 = \"llvm.icmp\"(%13, %5) <{predicate = 2 : i64}> : (i64, i64) -> i1\n%15 = \"llvm.sub\"(%6, %13) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%16 = \"llvm.select\"(%14, %15, %13) <{fastmathFlags = #llvm.fastmath<none>}> : (i1, i64, i64) -> i64\n%17 = \"llvm.sdiv\"(%16, %4) : (i64, i64) -> i64\n%18 = \"llvm.sub\"(%6, %17) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%19 = \"llvm.select\"(%14, %18, %17) <{fastmathFlags = #llvm.fastmath<none>}> : (i1, i64, i64) -> i64\n%20 = \"llvm.mul\"(%13, %7) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%21 = \"llvm.mul\"(%19, %8) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%22 = \"llvm.add\"(%20, %21) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%23 = \"llvm.mul\"(%19, %3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%24 = \"llvm.add\"(%23, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%25 = \"llvm.getelementptr\"(%arg1, %24) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%26 = \"llvm.load\"(%25) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%27 = \"llvm.add\"(%22, %9) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%28 = \"llvm.add\"(%23, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%29 = \"llvm.getelementptr\"(%arg1, %28) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%30 = \"llvm.load\"(%29) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%31 = \"llvm.add\"(%19, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%32 = \"llvm.mul\"(%31, %3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%33 = \"llvm.add\"(%32, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%34 = \"llvm.getelementptr\"(%arg1, %33) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%35 = \"llvm.load\"(%34) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%36 = \"llvm.add\"(%32, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%37 = \"llvm.getelementptr\"(%arg1, %36) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%38 = \"llvm.load\"(%37) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%39 = \"llvm.add\"(%22, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%40 = \"llvm.add\"(%23, %39) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%41 = \"llvm.getelementptr\"(%arg1, %40) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%42 = \"llvm.load\"(%41) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%43 = \"llvm.add\"(%22, %11) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%44 = \"llvm.add\"(%23, %43) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%45 = \"llvm.getelementptr\"(%arg1, %44) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%46 = \"llvm.load\"(%45) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%47 = \"llvm.add\"(%32, %39) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%48 = \"llvm.getelementptr\"(%arg1, %47) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%49 = \"llvm.load\"(%48) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%50 = \"llvm.add\"(%32, %43) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%51 = \"llvm.getelementptr\"(%arg1, %50) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%52 = \"llvm.load\"(%51) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%53 = \"llvm.mlir.undef\"() : () -> vector<2xf16>\n%54 = \"llvm.insertelement\"(%53, %26, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n%55 = \"llvm.shufflevector\"(%54, %54) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n%56 = \"llvm.insertelement\"(%55, %26, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%57 = \"llvm.insertelement\"(%56, %30, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%58 = \"llvm.insertelement\"(%55, %35, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%59 = \"llvm.insertelement\"(%58, %38, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%60 = \"llvm.insertelement\"(%55, %42, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%61 = \"llvm.insertelement\"(%60, %46, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%62 = \"llvm.insertelement\"(%55, %49, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%63 = \"llvm.insertelement\"(%62, %52, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%64 = \"llvm.mul\"(%22, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%65 = \"llvm.add\"(%64, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%66 = \"llvm.getelementptr\"(%arg8, %65) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%67 = \"llvm.load\"(%66) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%68 = \"llvm.mul\"(%27, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%69 = \"llvm.add\"(%68, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%70 = \"llvm.getelementptr\"(%arg8, %69) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%71 = \"llvm.load\"(%70) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%72 = \"llvm.mul\"(%39, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%73 = \"llvm.add\"(%72, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%74 = \"llvm.getelementptr\"(%arg8, %73) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%75 = \"llvm.load\"(%74) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%76 = \"llvm.mul\"(%43, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%77 = \"llvm.add\"(%76, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%78 = \"llvm.getelementptr\"(%arg8, %77) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%79 = \"llvm.load\"(%78) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%80 = \"llvm.insertelement\"(%53, %67, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n%81 = \"llvm.shufflevector\"(%80, %80) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n%82 = \"llvm.insertelement\"(%81, %67, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%83 = \"llvm.insertelement\"(%82, %71, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%84 = \"llvm.insertelement\"(%81, %75, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%85 = \"llvm.insertelement\"(%84, %79, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%86 = \"llvm.mul\"(%19, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%87 = \"llvm.add\"(%86, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%88 = \"llvm.getelementptr\"(%arg15, %87) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%89 = \"llvm.load\"(%88) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%90 = \"llvm.add\"(%86, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%91 = \"llvm.getelementptr\"(%arg15, %90) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%92 = \"llvm.load\"(%91) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%93 = \"llvm.mul\"(%31, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%94 = \"llvm.add\"(%93, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%95 = \"llvm.getelementptr\"(%arg15, %94) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%96 = \"llvm.load\"(%95) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%97 = \"llvm.add\"(%93, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%98 = \"llvm.getelementptr\"(%arg15, %97) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%99 = \"llvm.load\"(%98) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%100 = \"llvm.insertelement\"(%53, %89, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n%101 = \"llvm.shufflevector\"(%100, %100) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n%102 = \"llvm.insertelement\"(%101, %89, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%103 = \"llvm.insertelement\"(%102, %92, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%104 = \"llvm.insertelement\"(%101, %96, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%105 = \"llvm.insertelement\"(%104, %99, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%106 = \"nvvm.mma.sync\"(%57, %59, %61, %63, %83, %85, %103, %105) <{layoutA = #nvvm.mma_layout<row>, layoutB = #nvvm.mma_layout<col>, multiplicandAPtxType = #nvvm.mma_type<f16>, multiplicandBPtxType = #nvvm.mma_type<f16>, operandSegmentSizes = array<i32: 4, 2, 2>, shape = #nvvm.shape<m = 16, n = 8, k = 16>}> : (vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>) -> !llvm.struct<(vector<2xf16>, vector<2xf16>)>\n%107 = \"llvm.extractvalue\"(%106) <{position = array<i64: 0>}> : (!llvm.struct<(vector<2xf16>, vector<2xf16>)>) -> vector<2xf16>\n%108 = \"llvm.extractvalue\"(%106) <{position = array<i64: 1>}> : (!llvm.struct<(vector<2xf16>, vector<2xf16>)>) -> vector<2xf16>\n%109 = \"llvm.extractelement\"(%107, %1) : (vector<2xf16>, i64) -> f16\n%110 = \"llvm.extractelement\"(%107, %0) : (vector<2xf16>, i64) -> f16\n%111 = \"llvm.extractelement\"(%108, %1) : (vector<2xf16>, i64) -> f16\n%112 = \"llvm.extractelement\"(%108, %0) : (vector<2xf16>, i64) -> f16\n\"llvm.store\"(%109, %88) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n\"llvm.store\"(%110, %91) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n\"llvm.store\"(%111, %95) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n\"llvm.store\"(%112, %98) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n\"llvm.return\"() : () -> ()\n}) {gpu.kernel, gpu.known_block_size = array<i32: 32, 1, 1>, gpu.known_grid_size = array<i32: 1, 1, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 1, 1>} : () -> ()\n\"gpu.module_end\"() : () -> ()\n}) {sym_name = \"main_kernel\"} : () -> ()\n********************************************************************************\n\nFor developers, the error can be reproduced with:\n$ mlir-opt -mlir-print-ir-after-all -mlir-disable-threading -pass-pipeline='builtin.module(gpu-lower-to-nvvm-pipeline{ cubin-chip=sm_80 cubin-features=+ptx76 cubin-format=fatbin })' /tmp/UnnammedModule.mlir\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMLIRError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/mlir-pycuda2/lib/python3.12/site-packages/mlir/extras/runtime/passes.py:58\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(module, pipeline, description, enable_ir_printing, print_pipeline, verify)\u001b[0m\n\u001b[1;32m     56\u001b[0m             pm\u001b[38;5;241m.\u001b[39menable_ir_printing()\n\u001b[0;32m---> 58\u001b[0m         \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mMLIRError\u001b[0m: Failure while executing pass pipeline:\nerror: unknown: `ptxas` invocation failed. Log:\n  ptxas /tmp/mlir-main_kernel-nvptx64-nvidia-cuda-sm_80-12fe81.ptx, line 5; fatal   : Unsupported .version 7.6; current version is '7.5'\n  ptxas fatal   : Ptx assembly aborted due to errors\n  \nerror: unknown: An error happened while serializing the module.\n note: unknown: see current operation: \n  \"gpu.module\"() <{targets = [#nvvm.target<chip = \"sm_80\", features = \"+ptx76\">]}> ({\n    \"llvm.func\"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<void (ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64)>, linkage = #llvm.linkage<external>, sym_name = \"main_kernel\", visibility_ = 0 : i64}> ({\n    ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64):\n      %0 = \"llvm.mlir.constant\"() <{value = 1 : i64}> : () -> i64\n      %1 = \"llvm.mlir.constant\"() <{value = 0 : i64}> : () -> i64\n      %2 = \"llvm.mlir.constant\"() <{value = 0 : i32}> : () -> i32\n      %3 = \"llvm.mlir.constant\"() <{value = 16 : index}> : () -> i64\n      %4 = \"llvm.mlir.constant\"() <{value = 4 : index}> : () -> i64\n      %5 = \"llvm.mlir.constant\"() <{value = 0 : index}> : () -> i64\n      %6 = \"llvm.mlir.constant\"() <{value = -1 : index}> : () -> i64\n      %7 = \"llvm.mlir.constant\"() <{value = 2 : index}> : () -> i64\n      %8 = \"llvm.mlir.constant\"() <{value = -8 : index}> : () -> i64\n      %9 = \"llvm.mlir.constant\"() <{value = 1 : index}> : () -> i64\n      %10 = \"llvm.mlir.constant\"() <{value = 8 : index}> : () -> i64\n      %11 = \"llvm.mlir.constant\"() <{value = 9 : index}> : () -> i64\n      \"llvm.br\"()[^bb1] : () -> ()\n    ^bb1:  // pred: ^bb0\n      %12 = \"nvvm.read.ptx.sreg.tid.x\"() : () -> i32\n      %13 = \"llvm.sext\"(%12) : (i32) -> i64\n      %14 = \"llvm.icmp\"(%13, %5) <{predicate = 2 : i64}> : (i64, i64) -> i1\n      %15 = \"llvm.sub\"(%6, %13) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %16 = \"llvm.select\"(%14, %15, %13) <{fastmathFlags = #llvm.fastmath<none>}> : (i1, i64, i64) -> i64\n      %17 = \"llvm.sdiv\"(%16, %4) : (i64, i64) -> i64\n      %18 = \"llvm.sub\"(%6, %17) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %19 = \"llvm.select\"(%14, %18, %17) <{fastmathFlags = #llvm.fastmath<none>}> : (i1, i64, i64) -> i64\n      %20 = \"llvm.mul\"(%13, %7) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %21 = \"llvm.mul\"(%19, %8) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %22 = \"llvm.add\"(%20, %21) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %23 = \"llvm.mul\"(%19, %3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %24 = \"llvm.add\"(%23, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %25 = \"llvm.getelementptr\"(%arg1, %24) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %26 = \"llvm.load\"(%25) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %27 = \"llvm.add\"(%22, %9) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %28 = \"llvm.add\"(%23, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %29 = \"llvm.getelementptr\"(%arg1, %28) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %30 = \"llvm.load\"(%29) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %31 = \"llvm.add\"(%19, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %32 = \"llvm.mul\"(%31, %3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %33 = \"llvm.add\"(%32, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %34 = \"llvm.getelementptr\"(%arg1, %33) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %35 = \"llvm.load\"(%34) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %36 = \"llvm.add\"(%32, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %37 = \"llvm.getelementptr\"(%arg1, %36) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %38 = \"llvm.load\"(%37) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %39 = \"llvm.add\"(%22, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %40 = \"llvm.add\"(%23, %39) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %41 = \"llvm.getelementptr\"(%arg1, %40) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %42 = \"llvm.load\"(%41) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %43 = \"llvm.add\"(%22, %11) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %44 = \"llvm.add\"(%23, %43) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %45 = \"llvm.getelementptr\"(%arg1, %44) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %46 = \"llvm.load\"(%45) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %47 = \"llvm.add\"(%32, %39) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %48 = \"llvm.getelementptr\"(%arg1, %47) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %49 = \"llvm.load\"(%48) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %50 = \"llvm.add\"(%32, %43) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %51 = \"llvm.getelementptr\"(%arg1, %50) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %52 = \"llvm.load\"(%51) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %53 = \"llvm.mlir.undef\"() : () -> vector<2xf16>\n      %54 = \"llvm.insertelement\"(%53, %26, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n      %55 = \"llvm.shufflevector\"(%54, %54) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n      %56 = \"llvm.insertelement\"(%55, %26, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %57 = \"llvm.insertelement\"(%56, %30, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %58 = \"llvm.insertelement\"(%55, %35, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %59 = \"llvm.insertelement\"(%58, %38, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %60 = \"llvm.insertelement\"(%55, %42, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %61 = \"llvm.insertelement\"(%60, %46, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %62 = \"llvm.insertelement\"(%55, %49, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %63 = \"llvm.insertelement\"(%62, %52, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %64 = \"llvm.mul\"(%22, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %65 = \"llvm.add\"(%64, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %66 = \"llvm.getelementptr\"(%arg8, %65) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %67 = \"llvm.load\"(%66) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %68 = \"llvm.mul\"(%27, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %69 = \"llvm.add\"(%68, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %70 = \"llvm.getelementptr\"(%arg8, %69) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %71 = \"llvm.load\"(%70) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %72 = \"llvm.mul\"(%39, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %73 = \"llvm.add\"(%72, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %74 = \"llvm.getelementptr\"(%arg8, %73) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %75 = \"llvm.load\"(%74) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %76 = \"llvm.mul\"(%43, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %77 = \"llvm.add\"(%76, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %78 = \"llvm.getelementptr\"(%arg8, %77) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %79 = \"llvm.load\"(%78) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %80 = \"llvm.insertelement\"(%53, %67, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n      %81 = \"llvm.shufflevector\"(%80, %80) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n      %82 = \"llvm.insertelement\"(%81, %67, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %83 = \"llvm.insertelement\"(%82, %71, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %84 = \"llvm.insertelement\"(%81, %75, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %85 = \"llvm.insertelement\"(%84, %79, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %86 = \"llvm.mul\"(%19, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %87 = \"llvm.add\"(%86, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %88 = \"llvm.getelementptr\"(%arg15, %87) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %89 = \"llvm.load\"(%88) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %90 = \"llvm.add\"(%86, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %91 = \"llvm.getelementptr\"(%arg15, %90) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %92 = \"llvm.load\"(%91) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %93 = \"llvm.mul\"(%31, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %94 = \"llvm.add\"(%93, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %95 = \"llvm.getelementptr\"(%arg15, %94) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %96 = \"llvm.load\"(%95) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %97 = \"llvm.add\"(%93, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n      %98 = \"llvm.getelementptr\"(%arg15, %97) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n      %99 = \"llvm.load\"(%98) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n      %100 = \"llvm.insertelement\"(%53, %89, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n      %101 = \"llvm.shufflevector\"(%100, %100) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n      %102 = \"llvm.insertelement\"(%101, %89, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %103 = \"llvm.insertelement\"(%102, %92, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %104 = \"llvm.insertelement\"(%101, %96, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %105 = \"llvm.insertelement\"(%104, %99, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n      %106 = \"nvvm.mma.sync\"(%57, %59, %61, %63, %83, %85, %103, %105) <{layoutA = #nvvm.mma_layout<row>, layoutB = #nvvm.mma_layout<col>, multiplicandAPtxType = #nvvm.mma_type<f16>, multiplicandBPtxType = #nvvm.mma_type<f16>, operandSegmentSizes = array<i32: 4, 2, 2>, shape = #nvvm.shape<m = 16, n = 8, k = 16>}> : (vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>) -> !llvm.struct<(vector<2xf16>, vector<2xf16>)>\n      %107 = \"llvm.extractvalue\"(%106) <{position = array<i64: 0>}> : (!llvm.struct<(vector<2xf16>, vector<2xf16>)>) -> vector<2xf16>\n      %108 = \"llvm.extractvalue\"(%106) <{position = array<i64: 1>}> : (!llvm.struct<(vector<2xf16>, vector<2xf16>)>) -> vector<2xf16>\n      %109 = \"llvm.extractelement\"(%107, %1) : (vector<2xf16>, i64) -> f16\n      %110 = \"llvm.extractelement\"(%107, %0) : (vector<2xf16>, i64) -> f16\n      %111 = \"llvm.extractelement\"(%108, %1) : (vector<2xf16>, i64) -> f16\n      %112 = \"llvm.extractelement\"(%108, %0) : (vector<2xf16>, i64) -> f16\n      \"llvm.store\"(%109, %88) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n      \"llvm.store\"(%110, %91) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n      \"llvm.store\"(%111, %95) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n      \"llvm.store\"(%112, %98) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n      \"llvm.return\"() : () -> ()\n    }) {gpu.kernel, gpu.known_block_size = array<i32: 32, 1, 1>, gpu.known_grid_size = array<i32: 1, 1, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 1, 1>} : () -> ()\n    \"gpu.module_end\"() : () -> ()\n  }) {sym_name = \"main_kernel\"} : () -> ()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlirCompilerError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m backend \u001b[38;5;241m=\u001b[39m LLVMJITBackend([CUDA_RUNTIME_LIB_PATH])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# this doesn't actually anything (no pipeline) but does generate C API/wrappers\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m compiled_module \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfind_ops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransform.target_tag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattributes\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattributes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransform.target_tag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpayload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu-lower-to-nvvm-pipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcubin-chip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msm_80\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcubin-features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m+ptx76\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcubin-format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfatbin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(compiled_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlir-pycuda2/lib/python3.12/site-packages/mlir/extras/runtime/refbackend.py:289\u001b[0m, in \u001b[0;36mLLVMJITBackend.compile\u001b[0;34m(self, module, pipeline, kernel_name, enable_ir_printing, generate_kernel_wrapper, generate_return_consumer, return_consumer, verify)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto-llvm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pipeline \u001b[38;5;129;01mor\u001b[39;00m generate_kernel_wrapper:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_c_api(\n\u001b[1;32m    282\u001b[0m         module,\n\u001b[1;32m    283\u001b[0m         kernel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m         return_consumer,\n\u001b[1;32m    287\u001b[0m     )\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLowering IR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_ir_printing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_ir_printing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlir-pycuda2/lib/python3.12/site-packages/mlir/extras/runtime/passes.py:78\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(module, pipeline, description, enable_ir_printing, print_pipeline, verify)\u001b[0m\n\u001b[1;32m     67\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed with the following diagnostics:\u001b[39m\n\u001b[1;32m     69\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124m        $ mlir-opt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdebug_options\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -pass-pipeline=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     77\u001b[0m     trimmed_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mlstrip() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlirCompilerError(trimmed_message)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m original_stderr\n",
      "\u001b[0;31mMlirCompilerError\u001b[0m: Lowering IR failed with the following diagnostics:\n\n********************************************************************************\nFailure while executing pass pipeline:\nerror: unknown: `ptxas` invocation failed. Log:\nptxas /tmp/mlir-main_kernel-nvptx64-nvidia-cuda-sm_80-12fe81.ptx, line 5; fatal   : Unsupported .version 7.6; current version is '7.5'\nptxas fatal   : Ptx assembly aborted due to errors\n\nerror: unknown: An error happened while serializing the module.\nnote: unknown: see current operation: \n\"gpu.module\"() <{targets = [#nvvm.target<chip = \"sm_80\", features = \"+ptx76\">]}> ({\n\"llvm.func\"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<void (ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64)>, linkage = #llvm.linkage<external>, sym_name = \"main_kernel\", visibility_ = 0 : i64}> ({\n^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64):\n%0 = \"llvm.mlir.constant\"() <{value = 1 : i64}> : () -> i64\n%1 = \"llvm.mlir.constant\"() <{value = 0 : i64}> : () -> i64\n%2 = \"llvm.mlir.constant\"() <{value = 0 : i32}> : () -> i32\n%3 = \"llvm.mlir.constant\"() <{value = 16 : index}> : () -> i64\n%4 = \"llvm.mlir.constant\"() <{value = 4 : index}> : () -> i64\n%5 = \"llvm.mlir.constant\"() <{value = 0 : index}> : () -> i64\n%6 = \"llvm.mlir.constant\"() <{value = -1 : index}> : () -> i64\n%7 = \"llvm.mlir.constant\"() <{value = 2 : index}> : () -> i64\n%8 = \"llvm.mlir.constant\"() <{value = -8 : index}> : () -> i64\n%9 = \"llvm.mlir.constant\"() <{value = 1 : index}> : () -> i64\n%10 = \"llvm.mlir.constant\"() <{value = 8 : index}> : () -> i64\n%11 = \"llvm.mlir.constant\"() <{value = 9 : index}> : () -> i64\n\"llvm.br\"()[^bb1] : () -> ()\n^bb1:  // pred: ^bb0\n%12 = \"nvvm.read.ptx.sreg.tid.x\"() : () -> i32\n%13 = \"llvm.sext\"(%12) : (i32) -> i64\n%14 = \"llvm.icmp\"(%13, %5) <{predicate = 2 : i64}> : (i64, i64) -> i1\n%15 = \"llvm.sub\"(%6, %13) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%16 = \"llvm.select\"(%14, %15, %13) <{fastmathFlags = #llvm.fastmath<none>}> : (i1, i64, i64) -> i64\n%17 = \"llvm.sdiv\"(%16, %4) : (i64, i64) -> i64\n%18 = \"llvm.sub\"(%6, %17) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%19 = \"llvm.select\"(%14, %18, %17) <{fastmathFlags = #llvm.fastmath<none>}> : (i1, i64, i64) -> i64\n%20 = \"llvm.mul\"(%13, %7) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%21 = \"llvm.mul\"(%19, %8) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%22 = \"llvm.add\"(%20, %21) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%23 = \"llvm.mul\"(%19, %3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%24 = \"llvm.add\"(%23, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%25 = \"llvm.getelementptr\"(%arg1, %24) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%26 = \"llvm.load\"(%25) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%27 = \"llvm.add\"(%22, %9) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%28 = \"llvm.add\"(%23, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%29 = \"llvm.getelementptr\"(%arg1, %28) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%30 = \"llvm.load\"(%29) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%31 = \"llvm.add\"(%19, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%32 = \"llvm.mul\"(%31, %3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%33 = \"llvm.add\"(%32, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%34 = \"llvm.getelementptr\"(%arg1, %33) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%35 = \"llvm.load\"(%34) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%36 = \"llvm.add\"(%32, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%37 = \"llvm.getelementptr\"(%arg1, %36) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%38 = \"llvm.load\"(%37) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%39 = \"llvm.add\"(%22, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%40 = \"llvm.add\"(%23, %39) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%41 = \"llvm.getelementptr\"(%arg1, %40) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%42 = \"llvm.load\"(%41) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%43 = \"llvm.add\"(%22, %11) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%44 = \"llvm.add\"(%23, %43) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%45 = \"llvm.getelementptr\"(%arg1, %44) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%46 = \"llvm.load\"(%45) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%47 = \"llvm.add\"(%32, %39) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%48 = \"llvm.getelementptr\"(%arg1, %47) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%49 = \"llvm.load\"(%48) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%50 = \"llvm.add\"(%32, %43) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%51 = \"llvm.getelementptr\"(%arg1, %50) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%52 = \"llvm.load\"(%51) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%53 = \"llvm.mlir.undef\"() : () -> vector<2xf16>\n%54 = \"llvm.insertelement\"(%53, %26, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n%55 = \"llvm.shufflevector\"(%54, %54) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n%56 = \"llvm.insertelement\"(%55, %26, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%57 = \"llvm.insertelement\"(%56, %30, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%58 = \"llvm.insertelement\"(%55, %35, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%59 = \"llvm.insertelement\"(%58, %38, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%60 = \"llvm.insertelement\"(%55, %42, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%61 = \"llvm.insertelement\"(%60, %46, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%62 = \"llvm.insertelement\"(%55, %49, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%63 = \"llvm.insertelement\"(%62, %52, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%64 = \"llvm.mul\"(%22, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%65 = \"llvm.add\"(%64, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%66 = \"llvm.getelementptr\"(%arg8, %65) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%67 = \"llvm.load\"(%66) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%68 = \"llvm.mul\"(%27, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%69 = \"llvm.add\"(%68, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%70 = \"llvm.getelementptr\"(%arg8, %69) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%71 = \"llvm.load\"(%70) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%72 = \"llvm.mul\"(%39, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%73 = \"llvm.add\"(%72, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%74 = \"llvm.getelementptr\"(%arg8, %73) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%75 = \"llvm.load\"(%74) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%76 = \"llvm.mul\"(%43, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%77 = \"llvm.add\"(%76, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%78 = \"llvm.getelementptr\"(%arg8, %77) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%79 = \"llvm.load\"(%78) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%80 = \"llvm.insertelement\"(%53, %67, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n%81 = \"llvm.shufflevector\"(%80, %80) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n%82 = \"llvm.insertelement\"(%81, %67, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%83 = \"llvm.insertelement\"(%82, %71, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%84 = \"llvm.insertelement\"(%81, %75, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%85 = \"llvm.insertelement\"(%84, %79, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%86 = \"llvm.mul\"(%19, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%87 = \"llvm.add\"(%86, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%88 = \"llvm.getelementptr\"(%arg15, %87) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%89 = \"llvm.load\"(%88) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%90 = \"llvm.add\"(%86, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%91 = \"llvm.getelementptr\"(%arg15, %90) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%92 = \"llvm.load\"(%91) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%93 = \"llvm.mul\"(%31, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%94 = \"llvm.add\"(%93, %22) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%95 = \"llvm.getelementptr\"(%arg15, %94) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%96 = \"llvm.load\"(%95) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%97 = \"llvm.add\"(%93, %27) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64\n%98 = \"llvm.getelementptr\"(%arg15, %97) <{elem_type = f16, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr\n%99 = \"llvm.load\"(%98) <{ordering = 0 : i64}> : (!llvm.ptr) -> f16\n%100 = \"llvm.insertelement\"(%53, %89, %2) : (vector<2xf16>, f16, i32) -> vector<2xf16>\n%101 = \"llvm.shufflevector\"(%100, %100) <{mask = array<i32: 0, 0>}> : (vector<2xf16>, vector<2xf16>) -> vector<2xf16>\n%102 = \"llvm.insertelement\"(%101, %89, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%103 = \"llvm.insertelement\"(%102, %92, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%104 = \"llvm.insertelement\"(%101, %96, %1) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%105 = \"llvm.insertelement\"(%104, %99, %0) : (vector<2xf16>, f16, i64) -> vector<2xf16>\n%106 = \"nvvm.mma.sync\"(%57, %59, %61, %63, %83, %85, %103, %105) <{layoutA = #nvvm.mma_layout<row>, layoutB = #nvvm.mma_layout<col>, multiplicandAPtxType = #nvvm.mma_type<f16>, multiplicandBPtxType = #nvvm.mma_type<f16>, operandSegmentSizes = array<i32: 4, 2, 2>, shape = #nvvm.shape<m = 16, n = 8, k = 16>}> : (vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>, vector<2xf16>) -> !llvm.struct<(vector<2xf16>, vector<2xf16>)>\n%107 = \"llvm.extractvalue\"(%106) <{position = array<i64: 0>}> : (!llvm.struct<(vector<2xf16>, vector<2xf16>)>) -> vector<2xf16>\n%108 = \"llvm.extractvalue\"(%106) <{position = array<i64: 1>}> : (!llvm.struct<(vector<2xf16>, vector<2xf16>)>) -> vector<2xf16>\n%109 = \"llvm.extractelement\"(%107, %1) : (vector<2xf16>, i64) -> f16\n%110 = \"llvm.extractelement\"(%107, %0) : (vector<2xf16>, i64) -> f16\n%111 = \"llvm.extractelement\"(%108, %1) : (vector<2xf16>, i64) -> f16\n%112 = \"llvm.extractelement\"(%108, %0) : (vector<2xf16>, i64) -> f16\n\"llvm.store\"(%109, %88) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n\"llvm.store\"(%110, %91) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n\"llvm.store\"(%111, %95) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n\"llvm.store\"(%112, %98) <{ordering = 0 : i64}> : (f16, !llvm.ptr) -> ()\n\"llvm.return\"() : () -> ()\n}) {gpu.kernel, gpu.known_block_size = array<i32: 32, 1, 1>, gpu.known_grid_size = array<i32: 1, 1, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 1, 1>} : () -> ()\n\"gpu.module_end\"() : () -> ()\n}) {sym_name = \"main_kernel\"} : () -> ()\n********************************************************************************\n\nFor developers, the error can be reproduced with:\n$ mlir-opt -mlir-print-ir-after-all -mlir-disable-threading -pass-pipeline='builtin.module(gpu-lower-to-nvvm-pipeline{ cubin-chip=sm_80 cubin-features=+ptx76 cubin-format=fatbin })' /tmp/UnnammedModule.mlir\n"
     ]
    }
   ],
   "source": [
    "backend = LLVMJITBackend([CUDA_RUNTIME_LIB_PATH])\n",
    "# this doesn't actually anything (no pipeline) but does generate C API/wrappers\n",
    "compiled_module = backend.compile(\n",
    "    find_ops(\n",
    "        mod.operation,\n",
    "        lambda x: \"transform.target_tag\" in x.attributes\n",
    "                  and x.attributes[\"transform.target_tag\"].value == \"payload\",\n",
    "        single=True,\n",
    "    ),\n",
    "    Pipeline().add_pass(\n",
    "        \"gpu-lower-to-nvvm-pipeline\",\n",
    "        **{\n",
    "            \"cubin-chip\": \"sm_80\",\n",
    "            \"cubin-features\": \"+ptx76\",\n",
    "            \"cubin-format\": \"fatbin\",\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "print(compiled_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOapyydH8n4h"
   },
   "source": [
    "# Load and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:42:40.965581098Z",
     "start_time": "2024-02-02T23:42:40.831596632Z"
    },
    "id": "pOEC4Qgw8p9X"
   },
   "outputs": [],
   "source": [
    "backend.load(compiled_module).main_capi_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
